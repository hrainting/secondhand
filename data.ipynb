{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"darkgrid\")\n",
    "%matplotlib inline\n",
    "#设置图形的字体和线性颜色\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "r_hex = '#dc2624'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zz =pd.read_csv('df_zz_1106.csv')\n",
    "df_liuyan = pd.read_csv('df_liuya_1106.csv')\n",
    "df_comment = pd.read_csv('df_comment_1106.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21651 entries, 0 to 21650\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  21651 non-null  int64  \n",
      " 1   _id         19747 non-null  object \n",
      " 2   uid         21651 non-null  int64  \n",
      " 3   infoId      21651 non-null  int64  \n",
      " 4   留言用户名字      21092 non-null  object \n",
      " 5   留言用户id      21651 non-null  int64  \n",
      " 6   留言内容        21651 non-null  object \n",
      " 7   留言时间        21651 non-null  int64  \n",
      " 8   回复名字        11416 non-null  object \n",
      " 9   回复id        11641 non-null  float64\n",
      " 10  回复时间        11641 non-null  float64\n",
      " 11  回复内容        11641 non-null  object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_liuyan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2427451 entries, 0 to 2427450\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   Unnamed: 0  int64  \n",
      " 1   _id         object \n",
      " 2   uid         int64  \n",
      " 3   infoId      int64  \n",
      " 4   评论者         object \n",
      " 5   评论者身份       object \n",
      " 6   评分          int64  \n",
      " 7   评论标签        object \n",
      " 8   评论内容        object \n",
      " 9   评论时间        int64  \n",
      " 10  评论地点        object \n",
      " 11  卖家评价        object \n",
      " 12  卖家评价时间      float64\n",
      "dtypes: float64(1), int64(5), object(7)\n",
      "memory usage: 240.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_comment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zz.drop_duplicates(subset=['infoId'],keep='first',inplace=True)\n",
    "df_liuyan.drop_duplicates(subset=['infoId','留言用户id','留言时间'],keep='first',inplace=True)\n",
    "df_comment.drop_duplicates(subset=['infoId','评论者','评论时间'],keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 796129 entries, 0 to 2427450\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Unnamed: 0  796129 non-null  int64  \n",
      " 1   _id         650207 non-null  object \n",
      " 2   uid         796129 non-null  int64  \n",
      " 3   infoId      796129 non-null  int64  \n",
      " 4   评论者         781096 non-null  object \n",
      " 5   评论者身份       796129 non-null  object \n",
      " 6   评分          796129 non-null  int64  \n",
      " 7   评论标签        85889 non-null   object \n",
      " 8   评论内容        796129 non-null  object \n",
      " 9   评论时间        796129 non-null  int64  \n",
      " 10  评论地点        515882 non-null  object \n",
      " 11  卖家评价        14913 non-null   object \n",
      " 12  卖家评价时间      14913 non-null   float64\n",
      "dtypes: float64(1), int64(5), object(7)\n",
      "memory usage: 85.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_comment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_zz\n",
    "for i in['电脑','显卡','电动车','手机','苹果','晓龙','处理器','黄金','内存','三星','大侦探','典藏卡','小米','vivo','家具','钢琴','OPPO','华为','台式','游戏','纲手','一加','华硕','硬盘','不做了','手表','家用','新电池','和田玉','音质','原神','台式','热水器','回收','相机']:\n",
    "    data = data[data.apply(lambda x:i not in x['title'],axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>infoId</th>\n",
       "      <th>price</th>\n",
       "      <th>uid</th>\n",
       "      <th>userStatus</th>\n",
       "      <th>商品原价</th>\n",
       "      <th>是否包邮</th>\n",
       "      <th>想要量</th>\n",
       "      <th>浏览量</th>\n",
       "      <th>留言数</th>\n",
       "      <th>...</th>\n",
       "      <th>恶意砍价</th>\n",
       "      <th>售假劣质品被举报次数</th>\n",
       "      <th>被举报成立次数</th>\n",
       "      <th>欺诈被举报次数</th>\n",
       "      <th>勋章</th>\n",
       "      <th>来自卖家</th>\n",
       "      <th>有图</th>\n",
       "      <th>好评</th>\n",
       "      <th>中评</th>\n",
       "      <th>差评</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6548.000000</td>\n",
       "      <td>6.548000e+03</td>\n",
       "      <td>6548.000000</td>\n",
       "      <td>6.548000e+03</td>\n",
       "      <td>6548.000000</td>\n",
       "      <td>6532.000000</td>\n",
       "      <td>6532.0</td>\n",
       "      <td>6548.000000</td>\n",
       "      <td>6548.000000</td>\n",
       "      <td>6548.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6452.0</td>\n",
       "      <td>6452.000000</td>\n",
       "      <td>6452.0</td>\n",
       "      <td>6451.000000</td>\n",
       "      <td>6050.0</td>\n",
       "      <td>6548.000000</td>\n",
       "      <td>6548.000000</td>\n",
       "      <td>6548.000000</td>\n",
       "      <td>6548.000000</td>\n",
       "      <td>6548.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6966.027031</td>\n",
       "      <td>1.715325e+18</td>\n",
       "      <td>52.233812</td>\n",
       "      <td>6.690461e+17</td>\n",
       "      <td>0.110263</td>\n",
       "      <td>424.171310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.828955</td>\n",
       "      <td>16.304215</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.911118</td>\n",
       "      <td>1.013286</td>\n",
       "      <td>54.022144</td>\n",
       "      <td>0.621717</td>\n",
       "      <td>0.82193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5979.189251</td>\n",
       "      <td>2.999129e+16</td>\n",
       "      <td>266.172983</td>\n",
       "      <td>7.446734e+17</td>\n",
       "      <td>0.313241</td>\n",
       "      <td>17512.411854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.525234</td>\n",
       "      <td>625.191359</td>\n",
       "      <td>0.138061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.739885</td>\n",
       "      <td>6.302902</td>\n",
       "      <td>107.907147</td>\n",
       "      <td>1.532599</td>\n",
       "      <td>2.20544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.113587e+17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.553618e+13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1680.750000</td>\n",
       "      <td>1.717722e+18</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.096337e+16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4750.500000</td>\n",
       "      <td>1.718348e+18</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.896673e+17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12508.500000</td>\n",
       "      <td>1.718930e+18</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.599661e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18701.000000</td>\n",
       "      <td>1.719687e+18</td>\n",
       "      <td>16666.000000</td>\n",
       "      <td>1.719650e+18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999999.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>50454.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>33.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0        infoId         price           uid   userStatus  \\\n",
       "count   6548.000000  6.548000e+03   6548.000000  6.548000e+03  6548.000000   \n",
       "mean    6966.027031  1.715325e+18     52.233812  6.690461e+17     0.110263   \n",
       "std     5979.189251  2.999129e+16    266.172983  7.446734e+17     0.313241   \n",
       "min        0.000000  8.113587e+17      0.000000  3.553618e+13     0.000000   \n",
       "25%     1680.750000  1.717722e+18     19.000000  1.096337e+16     0.000000   \n",
       "50%     4750.500000  1.718348e+18     29.000000  1.896673e+17     0.000000   \n",
       "75%    12508.500000  1.718930e+18     46.000000  1.599661e+18     0.000000   \n",
       "max    18701.000000  1.719687e+18  16666.000000  1.719650e+18     1.000000   \n",
       "\n",
       "                商品原价    是否包邮          想要量           浏览量          留言数  ...  \\\n",
       "count    6532.000000  6532.0  6548.000000   6548.000000  6548.000000  ...   \n",
       "mean      424.171310     1.0     1.828955     16.304215     0.005651  ...   \n",
       "std     17512.411854     0.0    25.525234    625.191359     0.138061  ...   \n",
       "min         0.000000     1.0     0.000000      0.000000     0.000000  ...   \n",
       "25%         0.000000     1.0     0.000000      1.000000     0.000000  ...   \n",
       "50%         0.000000     1.0     0.000000      2.000000     0.000000  ...   \n",
       "75%        69.000000     1.0     0.000000      5.000000     0.000000  ...   \n",
       "max    999999.000000     1.0  1151.000000  50454.000000     9.000000  ...   \n",
       "\n",
       "         恶意砍价   售假劣质品被举报次数  被举报成立次数      欺诈被举报次数      勋章         来自卖家  \\\n",
       "count  6452.0  6452.000000   6452.0  6451.000000  6050.0  6548.000000   \n",
       "mean      0.0     0.010074      0.0     0.000775     0.0     5.911118   \n",
       "std       0.0     0.101412      0.0     0.027832     0.0    40.739885   \n",
       "min       0.0     0.000000      0.0     0.000000     0.0     0.000000   \n",
       "25%       0.0     0.000000      0.0     0.000000     0.0     0.000000   \n",
       "50%       0.0     0.000000      0.0     0.000000     0.0     0.000000   \n",
       "75%       0.0     0.000000      0.0     0.000000     0.0     1.000000   \n",
       "max       0.0     2.000000      0.0     1.000000     0.0   999.000000   \n",
       "\n",
       "                有图           好评           中评          差评  \n",
       "count  6548.000000  6548.000000  6548.000000  6548.00000  \n",
       "mean      1.013286    54.022144     0.621717     0.82193  \n",
       "std       6.302902   107.907147     1.532599     2.20544  \n",
       "min       0.000000     0.000000     0.000000     0.00000  \n",
       "25%       0.000000     1.000000     0.000000     0.00000  \n",
       "50%       0.000000    10.000000     0.000000     0.00000  \n",
       "75%       1.000000    44.000000     1.000000     1.00000  \n",
       "max     423.000000   661.000000    13.000000    33.00000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('data_clean1106.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel(\"D:/paper/secondhand/iv/result_clean.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6433 entries, 0 to 6432\n",
      "Data columns (total 57 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    6433 non-null   int64  \n",
      " 1   polluted      9 non-null      float64\n",
      " 2    authentic    9 non-null      float64\n",
      " 3   Image         6433 non-null   object \n",
      " 4   HasUpperBody  6433 non-null   bool   \n",
      " 5   _id           5485 non-null   object \n",
      " 6   infoId        6433 non-null   int64  \n",
      " 7   metric        6433 non-null   object \n",
      " 8   title         6433 non-null   object \n",
      " 9   price         6433 non-null   int64  \n",
      " 10  infoImage     6433 non-null   object \n",
      " 11  headImg       6433 non-null   object \n",
      " 12  nickName      6433 non-null   object \n",
      " 13  uid           6433 non-null   int64  \n",
      " 14  adTicket      61 non-null     object \n",
      " 15  userStatus    6433 non-null   int64  \n",
      " 16  labelText     6433 non-null   object \n",
      " 17  所有图片链接        6400 non-null   object \n",
      " 18  商品原价          6417 non-null   float64\n",
      " 19  是否包邮          6417 non-null   float64\n",
      " 20  商品标签          5249 non-null   object \n",
      " 21  商品说明          6433 non-null   object \n",
      " 22  发布地           6433 non-null   object \n",
      " 23  想要量           6433 non-null   int64  \n",
      " 24  浏览量           6433 non-null   int64  \n",
      " 25  留言数           6433 non-null   int64  \n",
      " 26  总评分           6433 non-null   float64\n",
      " 27  评论数           6433 non-null   int64  \n",
      " 28  交易次数          5066 non-null   float64\n",
      " 29  好评率           4898 non-null   float64\n",
      " 30  处罚记录          6427 non-null   object \n",
      " 31  关联账号信息        6427 non-null   object \n",
      " 32  实人认证          6427 non-null   float64\n",
      " 33  微信支付分         6427 non-null   float64\n",
      " 34  近期卖出          6427 non-null   float64\n",
      " 35  发货后被退货        6427 non-null   float64\n",
      " 36  近期买入          6427 non-null   float64\n",
      " 37  申请退款次数        6427 non-null   object \n",
      " 38  交易纠纷数         6427 non-null   object \n",
      " 39  恶意退货退款        6427 non-null   float64\n",
      " 40  恶意砍价          6427 non-null   float64\n",
      " 41  不诚信交易         6427 non-null   object \n",
      " 42  骚扰辱骂          6427 non-null   object \n",
      " 43  售假劣质品被举报次数    6427 non-null   float64\n",
      " 44  被举报成立次数       6427 non-null   float64\n",
      " 45  欺诈被举报次数       6427 non-null   float64\n",
      " 46  粉丝            5935 non-null   object \n",
      " 47  关注            5935 non-null   object \n",
      " 48  勋章            5935 non-null   float64\n",
      " 49  卖家简介          6198 non-null   object \n",
      " 50  全部            6433 non-null   object \n",
      " 51  来自买家          6433 non-null   object \n",
      " 52  来自卖家          6433 non-null   int64  \n",
      " 53  有图            6433 non-null   int64  \n",
      " 54  好评            6433 non-null   int64  \n",
      " 55  中评            6433 non-null   int64  \n",
      " 56  差评            6433 non-null   int64  \n",
      "dtypes: bool(1), float64(18), int64(14), object(24)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "# # 网络上图片的地址\n",
    "# img_src = 'https://pic1.zhuanstatic.com/zhuanzh/63076e9f-1cea-4088-9241-070daf00f2e0.jpg'\n",
    "\n",
    "# # 将远程数据下载到本地，第二个参数就是要保存到本地的文件名\n",
    "# urlretrieve(img_src,'D:/paper/二手产品/picture/1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data[['infoId','infoImage']].itertuples(index=False):\n",
    "    id,url = row\n",
    "    urlretrieve(url,f'D:/paper/二手产品/picture/head_{id}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1718836884414469888\n",
      "1718823344760179968\n",
      "1718824780418550016\n",
      "1718820211801400064\n",
      "1718825928441829888\n",
      "1718606135346860032\n",
      "1718606829359930112\n",
      "1718838692393769984\n",
      "1718824434195160064\n",
      "1718835896790640128\n",
      "1718827483901760000\n",
      "1718824733066510080\n",
      "1718821125104519936\n",
      "1718822098815140096\n",
      "1718806630390400000\n",
      "1718834054367389952\n",
      "1718827196124339968\n",
      "1718824307267830016\n",
      "1718836164175320064\n",
      "1718820969520349952\n",
      "1718562715820839936\n",
      "1718593950664019968\n",
      "1718613420027760128\n",
      "1718817294027869952\n",
      "1718839689850670080\n",
      "1718830443599749888\n",
      "1718829555068280064\n",
      "1718821696521609984\n",
      "1718837717398279936\n",
      "1718822107114949888\n",
      "1718810041852709888\n",
      "1718832610857179904\n",
      "1718818053719640064\n",
      "1718693862127960064\n",
      "1718839258373479936\n",
      "1718549480296580096\n",
      "1718271946984100096\n",
      "1718821677434129920\n",
      "1718814218281309952\n",
      "1718834066015930112\n",
      "1718824286181220096\n",
      "1718620908112199936\n",
      "1718838846234469888\n",
      "1718815976307840000\n",
      "1718818569515190016\n",
      "1526840241282400000\n",
      "1718812112252640000\n",
      "1718827262360519936\n",
      "1718823667107940096\n",
      "1718835939308379904\n",
      "1718786575412110080\n",
      "1718812495067579904\n",
      "1718813096227180032\n",
      "1718818288157870080\n",
      "1718830186518269952\n",
      "1718797378018139904\n",
      "1718820835675330048\n",
      "1718822375009799936\n",
      "1718585937932770048\n",
      "1718823548807650048\n",
      "1718831856025060096\n",
      "1718823501139640064\n",
      "1718833414191729920\n",
      "1718829274196709888\n",
      "1718612630391739904\n",
      "1718812834945319936\n",
      "1718810891332689920\n",
      "1718828103947620096\n",
      "1718815435078919936\n",
      "1718085297926080000\n",
      "1718823227754650112\n",
      "1718823808896960000\n",
      "1718618916975280128\n",
      "1718809946386880000\n",
      "1718809760367970048\n",
      "1718825686367569920\n",
      "1718823720035909888\n",
      "1718829054398400000\n",
      "1718815722845260032\n",
      "1718827425594449920\n",
      "1718813942031869952\n",
      "1718824083866619904\n",
      "1718827792377939968\n",
      "1718807780435709952\n",
      "1718823933232389888\n",
      "1718820522726490112\n",
      "1718835496905769984\n",
      "1718826764385370112\n",
      "1718841416101159936\n",
      "1718833158541400064\n",
      "1718820917036260096\n",
      "1718836913103719936\n",
      "1718825803022080000\n",
      "1718841440605410048\n",
      "1718857321247020032\n",
      "1718844588519920128\n",
      "1718837130538469888\n",
      "1718856937157250048\n",
      "1718608473330010112\n",
      "1718848935341250048\n",
      "1718845126717789952\n",
      "1718845393798309888\n",
      "1718842615310550016\n",
      "1718825929739470080\n",
      "1718841928239140096\n",
      "1718841132489939968\n",
      "1718833328489619968\n",
      "1718798900837750016\n",
      "1718821472729009920\n",
      "1718827420583379968\n",
      "1718832568907879936\n",
      "1718857962381199872\n",
      "1718834390471000064\n",
      "1718843655330990080\n",
      "1718841409997430016\n",
      "1718842406308659968\n",
      "1718553578829430016\n",
      "1718853941240110080\n",
      "1718853758771830016\n",
      "1718833625109090048\n",
      "1718849872013609984\n",
      "1718622196627529984\n",
      "1718845110510670080\n",
      "1718841555939089920\n",
      "1718837311635279872\n",
      "1718843862631680000\n",
      "1718831906009179904\n",
      "1718836419714949888\n",
      "1718844673601380096\n",
      "1718826714712260096\n",
      "1718607874605700096\n",
      "1718843839976620032\n",
      "1718833910460179968\n",
      "1718817270979010048\n",
      "1718815641111520000\n",
      "1718843000163539968\n",
      "1718842704704029952\n",
      "1718840007291290112\n",
      "1652902382050449920\n",
      "1718829976291549952\n",
      "1718843317999360000\n",
      "1718843032271119872\n",
      "1718841064697760000\n",
      "1718838981852300032\n",
      "1718849577444580096\n",
      "1718842056147190016\n",
      "1718848788957370112\n",
      "1718824857946390016\n",
      "1718843684240560128\n",
      "1718841737485090048\n",
      "1718607756272100096\n",
      "1718843799172879872\n",
      "1718824560029179904\n",
      "1718842065748100096\n",
      "1718605356954050048\n",
      "1718844981563950080\n",
      "1718837529813850112\n",
      "1718826299159579904\n",
      "1718842456250390016\n",
      "1718843375264339968\n",
      "1718616911039480064\n",
      "1718802333621029888\n",
      "1718912022990660096\n",
      "1718865399223589888\n",
      "1718909440267569920\n",
      "1718867045902850048\n",
      "1718886222427300096\n",
      "1718863748430629888\n",
      "1718900288256450048\n",
      "1718885200362870016\n",
      "1718862363897159936\n",
      "1718893327694810112\n",
      "1718864746377710080\n",
      "1718880896725639936\n",
      "1718910941870119936\n",
      "1718885605143810048\n",
      "1718866615287269888\n",
      "1718905879936179968\n",
      "1718892544940659968\n",
      "1718868019714690048\n",
      "1718865678343869952\n",
      "1718863605505019904\n",
      "1718907133902330112\n",
      "1718886964423369984\n",
      "1718920917697789952\n",
      "1718876487154810112\n",
      "1718902042829299968\n",
      "1718871741819330048\n",
      "1718893105875569920\n",
      "1718904530296049920\n",
      "1718802898171699968\n",
      "1718901451410560000\n",
      "1718876158014799872\n",
      "1718881961556009984\n",
      "1718861059716389888\n",
      "1718889340938789888\n",
      "1718908810271350016\n",
      "1718909680484450048\n",
      "1718899081361900032\n",
      "1718882073817289984\n",
      "1718910504989580032\n",
      "1718908149313060096\n",
      "1718865162808590080\n",
      "1718876973798939904\n",
      "1718802384820800000\n",
      "1718890446169070080\n",
      "1718909512631960064\n",
      "1718917576436260096\n",
      "1718901069203180032\n",
      "1718893826550390016\n",
      "1718925076017120000\n",
      "1718844457539800064\n",
      "1718906748994390016\n",
      "1718752924806749952\n",
      "1718900743003889920\n",
      "1718912862118970112\n",
      "1718900108130589952\n",
      "1718904576712709888\n",
      "1718861764724100096\n",
      "1718885866522830080\n",
      "1718882593330929920\n",
      "1718818855507549952\n",
      "1718860782831780096\n",
      "1718895657051300096\n",
      "1718900412141050112\n",
      "1718882056351419904\n",
      "1718921930353560064\n",
      "1718850851891810048\n",
      "1718813320373100032\n",
      "1718924489110200064\n",
      "1718915816042040064\n",
      "1718917575054939904\n",
      "1718879945793740032\n",
      "1718882029519200000\n",
      "1718916117568570112\n",
      "1718900495309260032\n",
      "1718891641081629952\n",
      "1718906442160440064\n",
      "1718872855985230080\n",
      "1718863714071379968\n",
      "1718910149497560064\n",
      "1718890597075650048\n",
      "1718854137829920000\n",
      "1718918029557060096\n",
      "1718898021302370048\n",
      "1718924851314729984\n",
      "1718891782907990016\n",
      "1718888529238579968\n",
      "1718887739758960128\n",
      "1718902274505890048\n",
      "1718891176753319936\n",
      "1718862142329929984\n",
      "1718920023760689920\n",
      "1718896580584839936\n",
      "1718896322632499968\n",
      "1718872977036090112\n",
      "1718852779268019968\n",
      "1718882095532819968\n",
      "1718907261493939968\n",
      "1718882260146639872\n",
      "1718887739801880064\n",
      "1718859846890380032\n",
      "1718893827479310080\n",
      "1718909655876239872\n",
      "1718917247055529984\n",
      "1718884557331010048\n",
      "1718926136109519872\n",
      "1718900412077430016\n",
      "1718808977724950016\n",
      "1718861244591099904\n",
      "1718916346067470080\n",
      "1718889222102099968\n",
      "1718918631000329984\n",
      "1718927031472950016\n",
      "1718890305653870080\n",
      "1718910953555040000\n",
      "1718911736947510016\n",
      "1718913537918729984\n",
      "1718912447977590016\n",
      "1718900819625319936\n",
      "1718901653998970112\n",
      "1718896185277769984\n",
      "1718868141348229888\n",
      "1718896962574240000\n",
      "1718901952265390080\n",
      "1718899246826569984\n",
      "1718897305595810048\n",
      "1718921036468000000\n",
      "1718862483408150016\n",
      "1718909693700310016\n",
      "1718892837959990016\n",
      "1718916958341929984\n",
      "1718905948550070016\n",
      "1718838032491340032\n",
      "1718906221116630016\n",
      "1718875998353560064\n",
      "1718911552943170048\n",
      "1718916512381240064\n",
      "1718811923128800000\n",
      "1718860624085769984\n",
      "1718909514324329984\n",
      "1718870631205609984\n",
      "1718911524110830080\n",
      "1718870907035010048\n",
      "1718925629283569920\n",
      "1718868328321910016\n",
      "1718863466091630080\n",
      "1718910709316519936\n",
      "1718845737680260096\n",
      "1718876210896979968\n",
      "1718912078214700032\n",
      "1718876074270459904\n",
      "1718912635367429888\n",
      "1718798435115650048\n",
      "1718811502134350080\n",
      "1718902972920420096\n",
      "1718900864043749888\n",
      "1718861522901799936\n",
      "1718881121890639872\n",
      "1718911232225939968\n",
      "1718861503550540032\n",
      "1718910810037819904\n",
      "1718914978645900032\n",
      "1718811646992600064\n",
      "1718913167855290112\n",
      "1718881213941029888\n",
      "1718876022476709888\n",
      "1718863831084160000\n",
      "1718911332766680064\n",
      "1718922372091940096\n",
      "1718891655862360064\n",
      "1718900058326340096\n",
      "1718906197513920000\n",
      "1718910018771849984\n",
      "1718902619988169984\n",
      "1718864336270220032\n",
      "1718810175551069952\n",
      "1718863168786779904\n",
      "1718868999867729920\n",
      "1718912446640529920\n",
      "1718926728136689920\n",
      "1718909245059109888\n",
      "1718865332430000128\n",
      "1718909397834500096\n",
      "1718850218929819904\n",
      "1718810795636969984\n",
      "1718758189741050112\n",
      "1718861367438070016\n",
      "1718921275805730048\n",
      "1718900079192049920\n",
      "1718910387962880000\n",
      "1718810488307729920\n",
      "1718921901985959936\n",
      "1718862333512110080\n",
      "1718903487449929984\n",
      "1718861094988669952\n",
      "1718870760575600128\n",
      "1718924448431800064\n",
      "1718891546214860032\n",
      "1718861574498279936\n",
      "1718864034459689984\n",
      "1718927343457870080\n",
      "1718906452905890048\n",
      "1718923229344760064\n",
      "1718869437385939968\n",
      "1718906190740920064\n",
      "1718924250842340096\n",
      "1718922107443940096\n",
      "1718851734323470080\n",
      "1718924042641280000\n",
      "1718865095304029952\n",
      "1718893472103340032\n",
      "1718876141197509888\n",
      "1718891732829240064\n",
      "1718904759852130048\n",
      "1718938882518909952\n",
      "1718805829718629888\n",
      "1718946767413380096\n",
      "1718916888022210048\n",
      "1718912281063399936\n",
      "1718962589954319872\n",
      "1718857926711510016\n",
      "1718932174155089920\n",
      "1718864585090729984\n",
      "1718851357708689920\n",
      "1718922353098560000\n",
      "1718956698771719936\n",
      "1718940609058480128\n",
      "1718946645201329920\n",
      "1718938101692130048\n",
      "1718868011857299968\n",
      "1718925460068310016\n",
      "1718866749852090112\n",
      "1718936869666249984\n",
      "1718947694633880064\n",
      "1718820432943340032\n",
      "1718938958611170048\n",
      "1718862177559500032\n",
      "1715667001373710080\n",
      "1718856800237690112\n",
      "1718937294971049984\n",
      "1718862599918279936\n",
      "1718951619420049920\n",
      "1718930309594160128\n",
      "1718940085903770112\n",
      "1718942704983310080\n",
      "1718959792976709888\n",
      "1718953073241809920\n",
      "1718950721711030016\n",
      "1718830897765090048\n",
      "1718794670944730112\n",
      "1718945069135960064\n",
      "1718947528349129984\n",
      "1718917528883579904\n",
      "1718839803877100032\n",
      "1718951551136389888\n",
      "1718812976869870080\n",
      "1718958160461189888\n",
      "1718867857233600000\n",
      "1718937437480930048\n",
      "1718912576808950016\n",
      "1718811592132879872\n",
      "1718939974325370112\n",
      "1718925737375830016\n",
      "1718891626170880000\n",
      "1718865667759579904\n",
      "1718869869142170112\n",
      "1718867359453220096\n",
      "1718932264414020096\n",
      "1718892915157280000\n",
      "1718943059860209920\n",
      "1718965346516389888\n",
      "1718946865196440064\n",
      "1718931258128009984\n",
      "1718950478054810112\n",
      "1718882600371689984\n",
      "1718863243100100096\n",
      "1718843225144869888\n",
      "1718827804407160064\n",
      "1718950533514089984\n",
      "1718851611771490048\n",
      "1718928386602279936\n",
      "1718943110639229952\n",
      "1718953873777039872\n",
      "1718886168041949952\n",
      "1718929384229769984\n",
      "1718941908817929984\n",
      "1718923643682710016\n",
      "1718946716961840128\n",
      "1718883218152150016\n",
      "1718952386051909888\n",
      "1718812650816379904\n",
      "1718810324445910016\n",
      "1718932746828219904\n",
      "1718876310050309888\n",
      "1718948476008780032\n",
      "1718937335412940032\n",
      "1718939359908039936\n",
      "1718943811146040064\n",
      "1718963594976250112\n",
      "1718941880904140032\n",
      "1718956088328310016\n",
      "1718922237576090112\n",
      "1718897442149489920\n",
      "1718871110068029952\n",
      "1718862053143859968\n",
      "1718909000029540096\n",
      "1718940780374820096\n",
      "1718861356177120000\n",
      "1718949856826949888\n",
      "1718943757191190016\n",
      "1718957157842490112\n",
      "1718830592943579904\n",
      "1718794461573469952\n",
      "1718957218853639936\n",
      "1718861885895990016\n",
      "1718925586660790016\n",
      "1718865586010660096\n",
      "1718910827462099968\n",
      "1718946825815790080\n",
      "1718845328870050048\n",
      "1718928813687249920\n",
      "1718863069610629888\n",
      "1718877255803899904\n",
      "1718825019288950016\n",
      "1718897801537100032\n",
      "1718887686919330048\n",
      "1718923106323369984\n",
      "1718945735329809920\n",
      "1718965294517390080\n",
      "1718828712480740096\n",
      "1718953630478050048\n",
      "1718949699596179968\n",
      "1718944975813939968\n",
      "1718941060907490048\n",
      "1718941232383089920\n",
      "1718954471948620032\n",
      "1718925718546480128\n",
      "1718502442389740032\n",
      "1718944214634569984\n",
      "1718861067649110016\n",
      "1718843878263200000\n",
      "1718793140132110080\n",
      "1718856423612699904\n",
      "1718911768106080000\n",
      "1718952919676420096\n",
      "1718939076238200064\n",
      "1718956361431320064\n",
      "1718829727366089984\n",
      "1718936744298119936\n",
      "1718925181751069952\n",
      "1718897881339960064\n",
      "1718957806848120064\n",
      "1718876090347229952\n",
      "1718953869136829952\n",
      "1718944438971109888\n",
      "1718937177860410112\n",
      "1718925038196819968\n",
      "1718876104763049984\n",
      "1718865303507310080\n",
      "1718938415102779904\n",
      "1718873270137740032\n",
      "1718937615376649984\n",
      "1718859455136349952\n",
      "1718866653832890112\n",
      "1718861737407160064\n",
      "1718865769043460096\n",
      "1718937823070200064\n",
      "1718937430265240064\n",
      "1718931031077360128\n",
      "1718937954276410112\n",
      "1718930810180150016\n",
      "1718931258769349888\n",
      "1718925384352989952\n",
      "1718870497323930112\n",
      "1718910991960689920\n",
      "1718856555108689920\n",
      "1718942844986449920\n",
      "1718865365652940032\n",
      "1718946818845639936\n",
      "1718964521595980032\n",
      "1718925493302560000\n",
      "811358685860658944\n",
      "1638782030653619968\n",
      "1719006479990919936\n",
      "1428639368828359936\n",
      "1593078609552539904\n",
      "1718981807414579968\n",
      "1718990336302860032\n",
      "1718967982054510080\n",
      "1719004634268910080\n",
      "1718968581822139904\n",
      "1718995164959990016\n",
      "1718985440043490048\n",
      "1718970046296809984\n",
      "1718973363668379904\n",
      "1718979481806380032\n",
      "1718990194273469952\n",
      "1718966307039150080\n",
      "1718979017985900032\n",
      "1718982781560079872\n",
      "1718967735582530048\n",
      "1718989201789949952\n",
      "1500666429873819904\n",
      "1718991865618990080\n",
      "1718966050386710016\n",
      "1718980704251249920\n",
      "1718964906271640064\n",
      "1718967144128339968\n",
      "1718996804908549888\n",
      "1718982889233060096\n",
      "1719005517531140096\n",
      "1718999358857629952\n",
      "1718971359474240000\n",
      "1718965981647930112\n",
      "1718967585105090048\n",
      "1718990612340300032\n",
      "1718977938701090048\n",
      "1718986525971030016\n",
      "1718993253122269952\n",
      "1688496221901169920\n",
      "1719004802551190016\n",
      "1718999309764239872\n",
      "1718988530292150016\n",
      "1718979197843840000\n",
      "1719005759061139968\n",
      "1718984269545560064\n",
      "1718982638928450048\n",
      "1718979183097189888\n",
      "1718969490743810048\n",
      "1719002198566899968\n",
      "1718987333346269952\n",
      "1718978153909459968\n",
      "1718987474745280000\n",
      "1718899912808369920\n",
      "1718983623818939904\n",
      "1718988689287399936\n",
      "1718995118352600064\n",
      "1718981963073390080\n",
      "1718981670305499904\n",
      "1718985464166289920\n",
      "1718995310052179968\n",
      "1718860749535729920\n",
      "1718972850398530048\n",
      "1718988506035980032\n",
      "1718865110116339968\n",
      "1718979092971820032\n",
      "1719001451010020096\n",
      "1718969659922909952\n",
      "1718983313263480064\n",
      "1718979776051830016\n",
      "1718965063371559936\n",
      "1718973719060140032\n",
      "1718979746700039936\n",
      "1718970168326380032\n",
      "1718969748887099904\n",
      "1718976470778579968\n",
      "1718998247552260096\n",
      "1718968103986060032\n",
      "1718986007230899968\n",
      "1718977168217840128\n",
      "1718994179220389888\n",
      "1718991433991559936\n",
      "1718993968932879872\n",
      "1718925867888019968\n",
      "1718970220328100096\n",
      "1718968948324489984\n",
      "1718985767612649984\n",
      "1718973893555770112\n",
      "1718871594583840000\n",
      "1718968967983320064\n",
      "1718898455774269952\n",
      "1718981777959229952\n",
      "1718992555640719872\n",
      "1718966597312730112\n",
      "1718969264835059968\n",
      "1718974877153609984\n",
      "1718982023143559936\n",
      "1718970267287490048\n",
      "1718967493110840064\n",
      "1718993212456150016\n",
      "1718970596887290112\n",
      "1718989401700239872\n",
      "1718967723680120064\n",
      "1718955607397040128\n",
      "1718992266971940096\n",
      "1718967223492600064\n",
      "1718868789695350016\n",
      "1718869199973779968\n",
      "1718986122494020096\n",
      "1718987044611760128\n",
      "1718987142729110016\n",
      "1718986722476630016\n",
      "1718979432140019968\n",
      "1718978690903310080\n",
      "1718979038623650048\n",
      "1718975556216790016\n",
      "1718982621051830016\n",
      "1718986086482690048\n",
      "1718954979476179968\n",
      "1718987473882319872\n",
      "1718981521326249984\n",
      "1718964279383790080\n",
      "1718991712993200128\n",
      "1719018134129349888\n",
      "1719032177288829952\n",
      "1719015615643559936\n",
      "1718992329425159936\n",
      "1719000065837680128\n",
      "1719018576135970048\n",
      "1719031220633440000\n",
      "1719019298204570112\n",
      "1719017601878070016\n",
      "1719019767984669952\n",
      "1718889836287500032\n",
      "1719007366381819904\n",
      "1719028706127320064\n",
      "1718891816034909952\n",
      "1719004825576930048\n",
      "1719018729495379968\n",
      "1718972390152460032\n",
      "1619923383621339904\n",
      "1719000405527569920\n",
      "1718930500098490112\n",
      "1719011557649910016\n",
      "1719018994294099968\n",
      "1719002323794040064\n",
      "1719011142687300096\n",
      "1718992063849449984\n",
      "1719036602512300032\n",
      "1718993292696560128\n",
      "1719008438198419968\n",
      "1642851024429850112\n",
      "1719022734892359936\n",
      "1719015324683290112\n",
      "1719032051438789888\n",
      "1719015265671830016\n",
      "1718884326911859968\n",
      "1616483460527030016\n",
      "1719018015008630016\n",
      "1607430650141479936\n",
      "1605236772904900096\n",
      "1719019064205629952\n",
      "1719004311913110016\n",
      "1719027922107049984\n",
      "1718992423473270016\n",
      "1719011557714299904\n",
      "1719031777303269888\n",
      "1719006668653680128\n",
      "1719006579182259968\n",
      "1605236224289939968\n",
      "1593277011713949952\n",
      "1719020322496839936\n",
      "1719016524403310080\n",
      "1719020687299330048\n",
      "1719026393627170048\n",
      "1719019345685370112\n",
      "1719021112880989952\n",
      "1719025534688240128\n",
      "1719009329484339968\n",
      "1719024399386609920\n",
      "1718891587704920064\n",
      "1718891609813090048\n",
      "1718892603000529920\n",
      "1719009116514830080\n",
      "1719118781706490112\n",
      "1719134078436999936\n",
      "1719045498590060032\n",
      "1719010495662000128\n",
      "1718987801462050048\n",
      "1719007009178340096\n",
      "1719046110374840064\n",
      "1718986910134000128\n",
      "1719056152324049920\n",
      "1719093586902129920\n",
      "1719000569207610112\n",
      "1718983722702970112\n",
      "1719042422153090048\n",
      "1719052874463940096\n",
      "1719119211287729920\n",
      "1718992396167830016\n",
      "1719011868615589888\n",
      "1718966443850089984\n",
      "1718957975607369984\n",
      "1718932768909499904\n",
      "1719002603967320064\n",
      "1719120868791360000\n",
      "1719050158950419968\n",
      "1719012924175800064\n",
      "1719002621964369920\n",
      "1718995952887600128\n",
      "1719049555535790080\n",
      "1719097568761760000\n",
      "1719100579211399936\n",
      "1718966888924549888\n",
      "1718999767542860032\n",
      "1719012243036480000\n",
      "1718982717435830016\n",
      "1719118394013580032\n",
      "1718936894475209984\n",
      "1718969903510409984\n",
      "1718983334838279936\n",
      "1718983952104379904\n",
      "1718976272052339968\n",
      "1719134353746319872\n",
      "1718934255280440064\n",
      "1619920775267569920\n",
      "1718994954542980096\n",
      "1719003729695630080\n",
      "1718077991919379968\n",
      "1718973386586409984\n",
      "1718883720811840000\n",
      "1719023106842710016\n",
      "1719048649397159936\n",
      "1718994408733819904\n",
      "1718918306657019904\n",
      "1718953163477910016\n",
      "1719129852289850112\n",
      "1719049166472339968\n",
      "1719000759040920064\n",
      "1667159334941900032\n",
      "1718931116437609984\n",
      "1666264607778739968\n",
      "1719121682872209920\n",
      "1718825898094370048\n",
      "1718984542060250112\n",
      "1719047753738289920\n",
      "1719104228427849984\n",
      "1718970498505270016\n",
      "1719002281032090112\n",
      "1718971940193639936\n",
      "1718960414953410048\n",
      "1657021565523269888\n",
      "1718973604437299968\n",
      "1719086594657619968\n",
      "1654478638888590080\n",
      "1718919153143059968\n",
      "1719037561487510016\n",
      "1719047518432450048\n",
      "1718890016741740032\n",
      "1719005197095800064\n",
      "1718979821201100032\n",
      "1718932335138769920\n",
      "1718889901176689920\n",
      "1719092227536590080\n",
      "1718979442814330112\n",
      "1719102458112790016\n",
      "1718956513859950080\n",
      "1719090947736999936\n",
      "1718976142672730112\n",
      "1718973391094030080\n",
      "1718992929965580032\n",
      "1718967342800640000\n",
      "1718984689022080000\n",
      "1718969213916339968\n",
      "1719127969309430016\n",
      "1718958587075059968\n",
      "1719175224634710016\n",
      "1719144077374919936\n",
      "1414034614477570048\n",
      "1719148847952019968\n",
      "1719192044408950016\n",
      "1719155782360800000\n",
      "1719192206812760064\n",
      "1719151276906210048\n",
      "1719155125051049984\n",
      "1719181689823920128\n",
      "1719207531650980096\n",
      "1719224266324770048\n",
      "1719157371385809920\n",
      "1719219570913319936\n",
      "1719167525040989952\n",
      "1719178878873179904\n",
      "1718951010449019904\n",
      "1719214552337489920\n",
      "1719196545221469952\n",
      "1719208463214710016\n",
      "1719192122790500096\n",
      "1719161151481200128\n",
      "1719172459532539904\n",
      "1719198941547350016\n",
      "1719154314258550016\n",
      "1719212333327030016\n",
      "1719175679961260032\n",
      "1719198330062119936\n",
      "1719214795776100096\n",
      "1719205989939909888\n",
      "1719186203522010112\n",
      "1719180591114560000\n",
      "1719206006330459904\n",
      "1719162123867480064\n",
      "1719185879084519936\n",
      "1719206694567399936\n",
      "1719042915948400128\n",
      "1719064015548809984\n",
      "1719153872391379968\n",
      "1719141739148460032\n",
      "1719194174051030016\n",
      "1719165326495450112\n",
      "1719200328524979968\n",
      "1719123837961230080\n",
      "1719213630303030016\n",
      "1719151905920410112\n",
      "1719191949152179968\n",
      "1719088447845060096\n",
      "1719191031859219968\n",
      "1719196799457449984\n",
      "1719168884370119936\n",
      "1719199529857520128\n",
      "1719203018297169920\n",
      "1719156716921929984\n",
      "1719189958541649920\n",
      "1719196731521080064\n",
      "1719185130599899904\n",
      "1719172616406619904\n",
      "1719181311284250112\n",
      "1719198198933609984\n",
      "1719179133126530048\n",
      "1719148232641679872\n",
      "1719212787580359936\n",
      "1719186356516430080\n",
      "1719171301665129984\n",
      "1719221262221639936\n",
      "1719159990583350016\n",
      "1719184512175709952\n",
      "1718977577930149888\n",
      "1719188911374550016\n",
      "1719173342309159936\n",
      "1719161888113870080\n",
      "1719197166367630080\n",
      "1719194189663879936\n",
      "1719219824782299904\n",
      "1719183526273210112\n",
      "1719202712148610048\n",
      "1719029556379849984\n",
      "1718993433733779968\n",
      "1719158000785509888\n",
      "1718971762166010112\n",
      "1719197480385619968\n",
      "1719152825544379904\n",
      "1719162335700000000\n",
      "1719158909285519872\n",
      "1719218228325700096\n",
      "1719038239506980096\n",
      "1719205395075170048\n",
      "1719201371474249984\n",
      "1719223985566469888\n",
      "1719152674104610048\n",
      "1719203970063500032\n",
      "1719200393339919872\n",
      "1719193671338180096\n",
      "1719206753359069952\n",
      "1719150003317989888\n",
      "1719187347272669952\n",
      "1719181315356369920\n",
      "1719200897099340032\n",
      "1719211035049710080\n",
      "1719208974898160128\n",
      "1719195208733299968\n",
      "1719187797483790080\n",
      "1719194566487249920\n",
      "1719168227131249920\n",
      "1719154603362099968\n",
      "1719207978868809984\n",
      "1719173836531899904\n",
      "1719160841517949952\n",
      "1719206281208369920\n",
      "1719206516477250048\n",
      "1719193896094899968\n",
      "1719174357073530112\n",
      "1719194090754639872\n",
      "1719167058098850048\n",
      "1719192139850080000\n",
      "1719206203340489984\n",
      "1719171752670680064\n",
      "1719186335393939968\n",
      "1719204837126870016\n",
      "1719162519172080128\n",
      "1719150749271150080\n",
      "1719190441016250112\n",
      "1719149068976329984\n",
      "1719219898643480064\n",
      "1719165510265619968\n",
      "1719026007537289984\n",
      "1718978713816960000\n",
      "1719156903422970112\n",
      "1719179810524529920\n",
      "1719017785211099904\n",
      "1719188233458599936\n",
      "1719161916798880000\n",
      "1719156979109339904\n",
      "1719156312729440000\n",
      "1719180937890899968\n",
      "1719219539817090048\n",
      "1719200742030680064\n",
      "1719196842370619904\n",
      "1719216588410210048\n",
      "1719150369262619904\n",
      "1719179578368890112\n",
      "1416212615817639936\n",
      "1719189904509360128\n",
      "1719192744973959936\n",
      "1719204589064539904\n",
      "1719167551383160064\n",
      "1719089523284250112\n",
      "1719206246043919872\n",
      "1719193930416849920\n",
      "1719149277915579904\n",
      "1719121135121270016\n",
      "1719156239309459968\n",
      "1719161086112620032\n",
      "1719175820150870016\n",
      "1719187105084950016\n",
      "1719221005982980096\n",
      "1719205436344900096\n",
      "1719030044911409920\n",
      "1719189442194099968\n",
      "1719209544166279936\n",
      "1719183174080209920\n",
      "1719194871700130048\n",
      "1719151341925910016\n",
      "1719166079966370048\n",
      "1719149074502340096\n",
      "1719195426539800064\n",
      "1719195861095310080\n",
      "1719188658979480064\n",
      "1719205050618340096\n",
      "1719087630491320064\n",
      "1719211343447460096\n",
      "1719193540866670080\n",
      "1719190830205720064\n",
      "1719025194928640000\n",
      "1719209242693769984\n",
      "1719187768301900032\n",
      "1719159162541270016\n",
      "1719192196460150016\n",
      "1719198325202769920\n",
      "1719209814868499968\n",
      "1719205562235340032\n",
      "1719024004841019904\n",
      "1719162768803849984\n",
      "1719190144429639936\n",
      "1719205793182109952\n",
      "1719023064457090048\n",
      "1719202899144529920\n",
      "1719162266611440128\n",
      "1719204011180359936\n",
      "1719023570566980096\n",
      "1719160756548750080\n",
      "1719021971043980032\n",
      "1719149024300320000\n",
      "1719017407192440064\n",
      "1719148732926220032\n",
      "1719028342669910016\n",
      "1719166021536930048\n",
      "1719165507269120000\n",
      "1719152859328630016\n",
      "1719166824561590016\n",
      "1719149235030540032\n",
      "1719147857268790016\n",
      "1719203930309989888\n",
      "1719222826656940032\n",
      "1719140297367699968\n",
      "1719135828356539904\n",
      "1719200211776359936\n",
      "1719155532028169984\n",
      "1717197200027800064\n",
      "1719284390005120000\n",
      "1718470055837929984\n",
      "1719171895080000000\n",
      "1719276923577639936\n",
      "1719287961190159872\n",
      "1718857943671429888\n",
      "1719253222222729984\n",
      "1719254820952039936\n",
      "1719187985802010112\n",
      "1719251743477570048\n",
      "1719288027507360000\n",
      "1719292697598400000\n",
      "1719273107372900096\n",
      "1719273106588339968\n",
      "1719273867303209984\n",
      "1719197652758439936\n",
      "1719220063254609920\n",
      "1719246623822970112\n",
      "1719269498688770048\n",
      "1719265552078540032\n",
      "1719163454973050112\n",
      "1719209511839930112\n",
      "1719184690369520128\n",
      "1719189120038510080\n",
      "1719254019547520000\n",
      "1719233494770949888\n",
      "1719270613884329984\n",
      "1719165847964329984\n",
      "1719139935073230080\n",
      "1719276686418840064\n",
      "1719275156101240064\n",
      "1719270735536790016\n",
      "1719232660300349952\n",
      "1719163023428329984\n",
      "1719235482874909952\n",
      "1719242817861900032\n",
      "1719267147291919872\n",
      "1719267862361989888\n",
      "1719233323065270016\n",
      "1719242833404270080\n",
      "1719261761355079936\n",
      "1719282666796080128\n",
      "1719224873753270016\n",
      "1719154717874919936\n",
      "1719268270981390080\n",
      "1719291736212280064\n",
      "1719157344770789888\n",
      "1719233736085669888\n",
      "1718172170955269888\n",
      "1719255603605819904\n",
      "1719276870903600128\n",
      "1719247312985560064\n",
      "1719279617188519936\n",
      "1719292529301639936\n",
      "1719269008615670016\n",
      "1719268607860809984\n",
      "1719280232145309952\n",
      "1719168720689880064\n",
      "1719239090480029952\n",
      "1719226991501580032\n",
      "1719233672440250112\n",
      "1719256374898330112\n",
      "1719248950921580032\n",
      "1719255939776189952\n",
      "1719250345211660032\n",
      "1719185585680669952\n",
      "1719261641340790016\n",
      "1719287288093710080\n",
      "1719241880827399936\n",
      "1719268762440780032\n",
      "1719259641982799872\n",
      "1719167955438439936\n",
      "1719212972687460096\n",
      "1719248909443040000\n",
      "1719229792440829952\n",
      "1719272433163099904\n",
      "1719265408667849984\n",
      "1719285341439859968\n",
      "1719267996139099904\n",
      "1719293180399330048\n",
      "1719282398547419904\n",
      "1719272507912049920\n",
      "1719166250423899904\n",
      "1719253543053910016\n",
      "1719240376528719872\n",
      "1719193545664989952\n",
      "1719283767539950080\n",
      "1719147208269880064\n",
      "1719164318409019904\n",
      "1719149900306210048\n",
      "1719232996928539904\n",
      "1719291575710309888\n",
      "1719186278304130048\n",
      "1719247877313679872\n",
      "1719253611323660032\n",
      "1719152495522480128\n",
      "1719293035661250048\n",
      "1719255749501060096\n",
      "1719256377622400000\n",
      "1719224548865499904\n",
      "1719249746778299904\n",
      "1719270940544669952\n",
      "1719274295002040064\n",
      "1719243204406020096\n",
      "1719245949008880128\n",
      "1719285207826550016\n",
      "1719187943774919936\n",
      "1719269162931209984\n",
      "1719250566533189888\n",
      "1719203338328839936\n",
      "1719229463597449984\n",
      "1719288658104770048\n",
      "1719293993672890112\n",
      "1719144623398619904\n",
      "1719188243934070016\n",
      "1719269315174540032\n",
      "1719282208283239936\n",
      "1719273984423040000\n",
      "1719246923925430016\n",
      "1719253660280209920\n",
      "1719218596718449920\n",
      "1719250211261910016\n",
      "1719292258649449984\n",
      "1719272947549799936\n",
      "1719252076149299968\n",
      "1719163596294759936\n",
      "1719236576305159936\n",
      "1719290072924100096\n",
      "1719227757038670080\n",
      "1719270625937329920\n",
      "1719249969766350080\n",
      "1719232684954289920\n",
      "1718175205236410112\n",
      "1719267166919150080\n",
      "1719233361056539904\n",
      "1719282390034550016\n",
      "1719230646263030016\n",
      "1719257999841860096\n",
      "1719268736350080000\n",
      "1719267202359840000\n",
      "1719256277870650112\n",
      "1719282798006490112\n",
      "1719287724581080064\n",
      "1719251305332179968\n",
      "1719183539728539904\n",
      "1719261528315790080\n",
      "1719226703738769920\n",
      "1719193362743010048\n",
      "1719264968905090048\n",
      "1719238172097120000\n",
      "1719268625594899968\n",
      "1719196954178080000\n",
      "1719254430064839936\n",
      "1719280803015229952\n",
      "1719276099832849920\n",
      "1719161540922330112\n",
      "1719271848054949888\n",
      "1719237992453179904\n",
      "1719289273863049984\n",
      "1719150406703450112\n",
      "1719262974695529984\n",
      "1719260717649100032\n",
      "1719247778762330112\n",
      "1719282721829540096\n",
      "1719232150428000000\n",
      "1719239599813680128\n",
      "1719150527027020032\n",
      "1719233927245629952\n",
      "1719253136940130048\n",
      "1719241191366020096\n",
      "1719259449351379968\n",
      "1719268306152900096\n",
      "1719163906354480128\n",
      "1719287407953070080\n",
      "1719250411551170048\n",
      "1719254806727249920\n",
      "1719269853194700032\n",
      "1719244227977809920\n",
      "1719274816270960128\n",
      "1719265158068290048\n",
      "1719279419058490112\n",
      "1719150229183729920\n",
      "1719249269934259968\n",
      "1719258608331150080\n",
      "1719248468653090048\n",
      "1719231618732859904\n",
      "1719287835533009920\n",
      "1719271068513949952\n",
      "1719286721249479936\n",
      "1719149566789880064\n",
      "1719265085687190016\n",
      "1719229470181169920\n",
      "1719287540476300032\n",
      "1719246597867670016\n",
      "1719152298910749952\n",
      "1719269147631770112\n",
      "1719285557216880128\n",
      "1719265197331170048\n",
      "1719289670025100032\n",
      "1719250078271770112\n",
      "1719289727588179968\n",
      "1719243541071500032\n",
      "1719265118167879936\n",
      "1719268099236120064\n",
      "1719289087281090048\n",
      "1719278203121370112\n",
      "1719265035674309888\n",
      "1719285691580960000\n",
      "1719287078364669952\n",
      "1719269709618170112\n",
      "1719288195362350080\n",
      "1719286125934690048\n",
      "1719150990560679936\n",
      "1719289382979520000\n",
      "1719161203154050048\n",
      "1719289264490439936\n",
      "1719266456230779904\n",
      "1719166444809309952\n",
      "1719167273821880064\n",
      "1719148413550939904\n",
      "1719148123040859904\n",
      "1719164850973789952\n",
      "1719159981265210112\n",
      "1719158000404480000\n",
      "1719153323541619968\n",
      "1719164576532090112\n",
      "1719154102734249984\n",
      "1719157659915079936\n",
      "1719153833908720128\n",
      "1719163086325240064\n",
      "1719163557832120064\n",
      "1719157385242690048\n",
      "1719138737488740096\n",
      "1719152029389110016\n",
      "1719149675155640064\n",
      "1719161818299059968\n",
      "1719147362445779968\n",
      "1719268924935200000\n",
      "1719150691678769920\n",
      "1719269959095369984\n",
      "1719267526843650048\n",
      "1719267750811099904\n",
      "1719192905686459904\n",
      "1719266959429779968\n",
      "1719255821262279936\n",
      "1719275920881029888\n",
      "1719268946672359936\n",
      "1719251989186119936\n",
      "1719269072730020096\n",
      "1699634573033129984\n",
      "1069754080775389952\n",
      "1719295046991150080\n",
      "1719344634757530112\n",
      "1719348690331699968\n",
      "1719301717224689920\n",
      "1719348159184260096\n",
      "1719330119842759936\n",
      "1719211115798749952\n",
      "1719368136208440064\n",
      "1719319794978720000\n",
      "1719346495639670016\n",
      "1719330469255810048\n",
      "1719344584277720064\n",
      "1719310667840539904\n",
      "1719323739580369920\n",
      "1719316948708559872\n",
      "1719337101243290112\n",
      "1719362491283079936\n",
      "1719310829910949888\n",
      "1719342892531490048\n",
      "1719311854903059968\n",
      "1719299664001129984\n",
      "1719323060651249920\n",
      "1719336354674119936\n",
      "1719307360027630080\n",
      "1719286906954629888\n",
      "1719344325197189888\n",
      "1719360256330210048\n",
      "1719220869987830016\n",
      "1719351358483660032\n",
      "1719314288448969984\n",
      "1719354525670180096\n",
      "1719337521638919936\n",
      "1719347955976620032\n",
      "1719334082368110080\n",
      "1719338623074129920\n",
      "1719354685402880000\n",
      "1719343287302589952\n",
      "1719359176454939904\n",
      "1719340436358909952\n",
      "1719298677220859904\n",
      "1719300239607729920\n",
      "1719365218136219904\n",
      "1719344643532809984\n",
      "1719247082479490048\n",
      "1719361041859239936\n",
      "1719173768146789888\n",
      "1719227110956869888\n",
      "1719248438312410112\n",
      "1719347017122530048\n",
      "1719331319407909888\n",
      "1656487249405090048\n",
      "1719333589247729920\n",
      "1719237950331610112\n",
      "1719315115583099904\n",
      "1719357390446609920\n",
      "1719331728623689984\n",
      "1719330244521779968\n",
      "1719360317371620096\n",
      "1719311234596620032\n",
      "1719336446783539968\n",
      "1719355787140720128\n",
      "1719354342838520064\n",
      "1719182707839770112\n",
      "1719320495775049984\n",
      "1719303654172740096\n",
      "1719364893583970048\n",
      "1719297186641159936\n",
      "1719336473962830080\n",
      "1719213220046560000\n",
      "1719324572875889920\n",
      "1719345925388730112\n",
      "1719214489648890112\n",
      "1719349770767800064\n",
      "1719351206780900096\n",
      "1719364274032480000\n",
      "1719229938678340096\n",
      "1719245222266429952\n",
      "1719307448093430016\n",
      "1627540745193920000\n",
      "1719192429787190016\n",
      "1719218688559909888\n",
      "1719190317506789888\n",
      "1719187309671219968\n",
      "1719324564935020032\n",
      "1578980413562060032\n",
      "1719298220261499904\n",
      "1719240214960849920\n",
      "1675121524868489984\n",
      "1719193289422589952\n",
      "1719302783233939968\n",
      "1719350582223950080\n",
      "1719344043738569984\n",
      "1719237537221910016\n",
      "1719336281983770112\n",
      "1719221302010550016\n",
      "1719345976432460032\n",
      "1719348178484069888\n",
      "1719354582881440000\n",
      "1719252016874030080\n",
      "1719362142371830016\n",
      "1719210517837890048\n",
      "1719331948542500096\n",
      "1719344786415079936\n",
      "1719347211390360064\n",
      "1719348147719660032\n",
      "1719351605044790016\n",
      "1719302432793929984\n",
      "1719332477345029888\n",
      "1719362362591660032\n",
      "1719355307882680064\n",
      "1719351264829050112\n",
      "1719299313497390080\n",
      "1719332304640430080\n",
      "1719344147148989952\n",
      "1719348711076600064\n",
      "1719353008598490112\n",
      "1719348175629929984\n",
      "1719288322796470016\n",
      "1719334989362190080\n",
      "1719182511084659968\n",
      "1719345357481459968\n",
      "1719231444623330048\n",
      "1719318464429360128\n",
      "1719358945555680000\n",
      "1719243462281430016\n",
      "1719323307323510016\n",
      "1719334911866800128\n",
      "1719179757410929920\n",
      "1719357928743589888\n",
      "1719231141101410048\n",
      "1719359178749680128\n",
      "1719348435553999872\n",
      "1719357812019859968\n",
      "1719331113433799936\n",
      "1719245537510820096\n",
      "1719350047255119872\n",
      "1719352229535749888\n",
      "1719348348540310016\n",
      "1719359515226490112\n",
      "1719302705394319872\n",
      "1719344836445100032\n",
      "1719335644999930112\n",
      "1719350499367600128\n",
      "1719220517727460096\n",
      "1719288947166170112\n",
      "1719355502922010112\n",
      "1719247384686500096\n",
      "1719362254777649920\n",
      "1719351156771200000\n",
      "1719326172836420096\n",
      "1719344679431330048\n",
      "1719354275433779968\n",
      "1719289514251190016\n",
      "1719352040456519936\n",
      "1719351969706040064\n",
      "1719237331416630016\n",
      "1719250372618749952\n",
      "1719288075644329984\n",
      "1719353608059899904\n",
      "1719181995661459968\n",
      "1719352696268539904\n",
      "1719342773052790016\n",
      "1719343777643120128\n",
      "1719346714287350016\n",
      "1719353162842919936\n",
      "1719346443519859968\n",
      "1719347420620720128\n",
      "1719346007435790080\n",
      "1719351470495780096\n",
      "1719347520172529920\n",
      "1719345276075000064\n",
      "1719147010354929920\n",
      "1719353614881230080\n",
      "1719344138154249984\n",
      "1719359928149690112\n",
      "1719351316343620096\n",
      "1719368302375000064\n",
      "1719373987455059968\n",
      "1719390650695640064\n",
      "1719298908397440000\n",
      "1719485300322929920\n",
      "1719362604516969984\n",
      "1719452032645420032\n",
      "1719402136949659904\n",
      "1719497666887360000\n",
      "1719327321098409984\n",
      "1719264711328240128\n",
      "1719427442679940096\n",
      "1719413814464679936\n",
      "1719330396283539968\n",
      "1719306614576829952\n",
      "1719332909197280000\n",
      "1719390192698970112\n",
      "1719247944103780096\n",
      "1719372915986550016\n",
      "1719365956790880000\n",
      "1719500248805639936\n",
      "1719361218089829888\n",
      "1719347019976199936\n",
      "1719402635211709952\n",
      "1719441650565799936\n",
      "1719400051254050048\n",
      "1719336107696560128\n",
      "1719354124768270080\n",
      "1719325072644529920\n",
      "1719394662371099904\n",
      "1719358654802919936\n",
      "1719369798237920000\n",
      "1719328228604300032\n",
      "1719264147230759936\n",
      "1719373969506830080\n",
      "1719416219907970048\n",
      "1719312074116620032\n",
      "1719258722547810048\n",
      "1719387297092329984\n",
      "1719309454776999936\n",
      "1719259376719069952\n",
      "1719371922050469888\n",
      "1719358855482139904\n",
      "1719384613071950080\n",
      "1719259012623160064\n",
      "1719276506312989952\n",
      "1719369281005819904\n",
      "1719354014258269952\n",
      "1719282805785740032\n",
      "1719332256647990016\n",
      "1719362104218259968\n",
      "1719287340268460032\n",
      "1719272085933590016\n",
      "1719366873482629888\n",
      "1719332234277720064\n",
      "1719287408764100096\n",
      "1719341771308320000\n",
      "1719298585516250112\n",
      "1719313185219840000\n",
      "1719251813852009984\n",
      "1719498170360630016\n",
      "1719370479368359936\n",
      "1719349578974089984\n",
      "1719081868802400000\n",
      "1719334494441410048\n",
      "1718793901057679872\n",
      "1719302191284689920\n",
      "1719379297615089920\n",
      "1719326323966660096\n",
      "1719457235369149952\n",
      "1718793223279119872\n",
      "1717641321592130048\n",
      "1719312802241139968\n",
      "1702528999388470016\n",
      "1719266112305469952\n",
      "1719307950181639936\n",
      "1702316433752049920\n",
      "1719480740908649984\n",
      "1719370673955310080\n",
      "1719292185051160064\n",
      "1719392625200580096\n",
      "1681953494729740032\n",
      "1719251434849619968\n",
      "1719258615396829952\n",
      "1719329326180750080\n",
      "1719410245377769984\n",
      "1719362529462949888\n",
      "1719286881201890048\n",
      "1719327813435219968\n",
      "1719404957046739968\n",
      "1719310500398170112\n",
      "1719265752692890112\n",
      "1719401230386160128\n",
      "1719366844414660096\n",
      "1719364853483379968\n",
      "1719252844994579968\n",
      "1719357703248100096\n",
      "1719345574244239872\n",
      "1719439714075229952\n",
      "1719372892090309888\n",
      "1719354804775360000\n",
      "1719257755958779904\n",
      "1719373177195630080\n",
      "1719333667064480000\n",
      "1719327172390479872\n",
      "1719342440607079936\n",
      "1719290774422939904\n",
      "1719414213980529920\n",
      "1719255755397979904\n",
      "1719377608803739904\n",
      "1719372679791549952\n",
      "1719371948609969920\n",
      "1719333807137590016\n",
      "1719338104944270080\n",
      "1719254989615170048\n",
      "1719332424531279872\n",
      "1719301432028790016\n",
      "1719264017747630080\n",
      "1719305201935310080\n",
      "1719370842999820032\n",
      "1719375681781090048\n",
      "1719353077514830080\n",
      "1719384263293519872\n",
      "1719373754408829952\n",
      "1719289672565199872\n",
      "1719413494867369984\n",
      "1719375716429890048\n",
      "1719204612906550016\n",
      "1719339807596809984\n",
      "1719351557578889984\n",
      "1719255730541959936\n",
      "1719381766374020096\n",
      "1719375135140150016\n",
      "1719374234917839872\n",
      "1719351659353669888\n",
      "1719350103191259904\n",
      "1719365274071409920\n",
      "1719371850565410048\n",
      "1719347178008150016\n",
      "1719351457452460032\n",
      "1719366649815699968\n",
      "1719367083485760000\n",
      "1719367414290520064\n",
      "1719370011298700032\n",
      "1719265889748080128\n",
      "1719367831476969984\n",
      "1719322418951119872\n",
      "1719366164077550080\n",
      "1719266163527079936\n",
      "1719287264000369920\n",
      "1719353574938319872\n",
      "1719499180640489984\n",
      "1719414181904189952\n",
      "1719235971698319872\n",
      "1719447072899470080\n",
      "1719539126635089920\n",
      "1719542993358889984\n",
      "1719531815972209920\n",
      "1719537997963120128\n",
      "1719498546865359872\n",
      "1719536192447010048\n",
      "1719502797848240128\n",
      "1719531743725210112\n",
      "1719554692729669888\n",
      "1719559334841029888\n",
      "1719536737363919872\n",
      "1719553849296029952\n",
      "1719531094464859904\n",
      "1719542954699130112\n",
      "1719549026419859968\n",
      "1719555948487709952\n",
      "1719531126637969920\n",
      "1719533368859919872\n",
      "1719548107797339904\n",
      "1719505728852410112\n",
      "1719405493967980032\n",
      "1719501191683980032\n",
      "1719511119460750080\n",
      "1719552710941139968\n",
      "1719372168684329984\n",
      "1719380275861969920\n",
      "1719373748851350016\n",
      "1719523093089799936\n",
      "1719514902783180032\n",
      "1719550127973139968\n",
      "1719516547466759936\n",
      "1719550148081230080\n",
      "1719373289797489920\n",
      "1719514438859000064\n",
      "1719545264310929920\n",
      "1719549074269900032\n",
      "1719502387580199936\n",
      "1719531031979869952\n",
      "1719500532382060032\n",
      "1719541108007490048\n",
      "1719373905245880064\n",
      "1719528941934530048\n",
      "1719554589140780032\n",
      "1719514551106340096\n",
      "1719544401251320064\n",
      "1719515647716709888\n",
      "1719543043912140032\n",
      "1719552660008969984\n",
      "1719540705224940032\n",
      "1719400750536760064\n",
      "1719517115049410048\n",
      "1719546235196590080\n",
      "1719523065928730112\n",
      "1719515156439960064\n",
      "1719525209551290112\n",
      "1719228032897570048\n",
      "1719528134303960064\n",
      "1719554463172369920\n",
      "1719529260270700032\n",
      "1719519117368689920\n",
      "1719535334066299904\n",
      "1719546328156389888\n",
      "1719547361726190080\n",
      "1719336720940849920\n",
      "1719514058245380096\n",
      "1719549785125850112\n",
      "1719531663406159872\n",
      "1719539367280950016\n",
      "1719313626000630016\n",
      "1719512265460059904\n",
      "1719388908891229952\n",
      "1719507819394309888\n",
      "1719554776544069888\n",
      "1719562754602080000\n",
      "1719511913172339968\n",
      "1719524973618710016\n",
      "1719531644234650112\n",
      "1719538141151219968\n",
      "1719548322844369920\n",
      "1719526778245120000\n",
      "1719435280736329984\n",
      "1719548232850230016\n",
      "1719325199219150080\n",
      "1719560981457649920\n",
      "1719546614558820096\n",
      "1719551248813070080\n",
      "1719539777528580096\n",
      "1719547544987279872\n",
      "1719439641612910080\n",
      "1719530793870279936\n",
      "1719554467973700096\n",
      "1719559518945809920\n",
      "1719511251077370112\n",
      "1719501910042860032\n",
      "1719507890389600000\n",
      "1719546125993690112\n",
      "1719513368585870080\n",
      "1719552801689149952\n",
      "1719541291648859904\n",
      "1719537714502799872\n",
      "1719360749896140032\n",
      "1719433948220260096\n",
      "1719522903990850048\n",
      "1719555066402249984\n",
      "1719517554956410112\n",
      "1719537678807290112\n",
      "1719518656475909888\n",
      "1719551302210490112\n",
      "1719538960016989952\n",
      "1719389188642480128\n",
      "1719311685073260032\n",
      "1719524025640849920\n",
      "1719548623650309888\n",
      "1719552387626080000\n",
      "1719354830349570048\n",
      "1719361701409349888\n",
      "1719546036667620096\n",
      "1719547824038510080\n",
      "1719508878808389888\n",
      "1719501412493410048\n",
      "1719562465442860032\n",
      "1719508775018650112\n",
      "1719537471412359936\n",
      "1719538960880229888\n",
      "1719415584441700096\n",
      "1719329744375450112\n",
      "1719546867450190080\n",
      "1719556755378510080\n",
      "1719560161278299904\n",
      "1719515456479010048\n",
      "1719548327526960128\n",
      "1719388721526799872\n",
      "1719546254800790016\n",
      "1719515809912029952\n",
      "1719548602887209984\n",
      "1719547145457050112\n",
      "1718866780775340032\n",
      "1719546843951310080\n",
      "1719507204401619968\n",
      "1719563097990040064\n",
      "1719547111602429952\n",
      "1719379586858469888\n",
      "1719542923006870016\n",
      "1719297551529609984\n",
      "1719547873820219904\n",
      "1719412013440630016\n",
      "1719401316539369984\n",
      "1719487596981199872\n",
      "1719388221343470080\n",
      "1719392799841520128\n",
      "1719395200233309952\n",
      "1719399541916770048\n",
      "1719412405704529920\n",
      "1719411749581169920\n",
      "1719390033924529920\n",
      "1719387292342880000\n",
      "1719398739445750016\n",
      "1719402562608369920\n",
      "1719400100124100096\n",
      "1719394354208640000\n",
      "1719386884534899968\n",
      "1719393184438230016\n",
      "1719397491690639872\n",
      "1719396225094720000\n",
      "1719390555217789952\n",
      "1719411313209969920\n",
      "1719411010595130112\n",
      "1719389151858200064\n",
      "1719543683120369920\n",
      "1719461063483269888\n",
      "1719309619615170048\n",
      "1719418097292250112\n",
      "1719569436233189888\n",
      "1719583732358700032\n",
      "1719585638574850048\n",
      "1719568064758439936\n",
      "1719502788690889984\n",
      "1719571287417929984\n",
      "1719571836392560128\n",
      "1719575701127749888\n",
      "1719549662763950080\n",
      "1719563038729019904\n",
      "1719551439709519872\n",
      "1719568024852389888\n",
      "1719407876226540032\n",
      "1719566943531569920\n",
      "1719569087381260032\n",
      "1719234885605149952\n",
      "1719578355596329984\n",
      "1719565142502050048\n",
      "1719582665807340032\n",
      "1719569105312699904\n",
      "1719426609401479936\n",
      "1719574643856379904\n",
      "1719531968241420032\n",
      "1719558595737570048\n",
      "1719575938199069952\n",
      "1719575467097400064\n",
      "1719451861964169984\n",
      "1719569157288430080\n",
      "1719560227429410048\n",
      "1719559530417120000\n",
      "1719570676376869888\n",
      "1719582157238490112\n",
      "1719559619385270016\n",
      "1719576847945110016\n",
      "1719551287157659904\n",
      "1719558227448679936\n",
      "1719329571561309952\n",
      "1719584052782680064\n",
      "1719561423100910080\n",
      "1719568143215920128\n",
      "1719584534255099904\n",
      "1719511803398020096\n",
      "1719572024884580096\n",
      "1719581076111549952\n",
      "1719582846503800064\n",
      "1719575864344940032\n",
      "1719562797576160000\n",
      "1719364529409329920\n",
      "1719547515690670080\n",
      "1719553464389129984\n",
      "1719578803998429952\n",
      "1719344448387310080\n",
      "1719549842603840000\n",
      "1719576870071310080\n",
      "1719563674946830080\n",
      "1719582193690990080\n",
      "1719570275524499968\n",
      "1719326308709570048\n",
      "1719554126205029888\n",
      "1719572212458050048\n",
      "1719567263671049984\n",
      "1719361972942609920\n",
      "1719576748605809920\n",
      "1719570386856649984\n",
      "1719583683402909952\n",
      "1719449897608029952\n",
      "1719582910963109888\n",
      "1719573055324640000\n",
      "1719559751356389888\n",
      "1719572492658530048\n",
      "1719576054385580032\n",
      "1719454358057390080\n",
      "1719565280918690048\n",
      "1719563711386030080\n",
      "1719566329830230016\n",
      "1719412799327379968\n",
      "1719579702489649920\n",
      "1719545014628260096\n",
      "1719559540462030080\n",
      "1719562425709169920\n",
      "1719550177212829952\n",
      "1719583496183630080\n",
      "1414035389098409984\n",
      "1719604269174020096\n",
      "1719588895043150080\n",
      "1719650782382479872\n",
      "1719645696446569984\n",
      "1719629870046500096\n",
      "1719608968352719872\n",
      "1719638279419120128\n",
      "1719660104137179904\n",
      "1719612829162099968\n",
      "1719613839285230080\n",
      "1719617013787840000\n",
      "1719649739496079872\n",
      "1719547888223379968\n",
      "1719593576284080128\n",
      "1719507271889740032\n",
      "1719620749064659968\n",
      "1719636835160989952\n",
      "1719583622992240128\n",
      "1719643635715099904\n",
      "1719639812938680064\n",
      "1719616142999670016\n",
      "1719460195774479872\n",
      "1719631855940420096\n",
      "1719635133850569984\n",
      "1719587610386010112\n",
      "1719642370153499904\n",
      "1719635475973050112\n",
      "1719592813626200064\n",
      "1719644921366909952\n",
      "1719590506735899904\n",
      "1719605639969900032\n",
      "1719629669908080128\n",
      "1719621515980329984\n",
      "1719592370265509888\n",
      "1719653357222220032\n",
      "1719600863078269952\n",
      "1719665077392460032\n",
      "1719515749619389952\n",
      "1719610344737760000\n",
      "1719631827182060032\n",
      "1719610470307709952\n",
      "1719600118210380032\n",
      "1719643279849740032\n",
      "1719618714006980096\n",
      "1719587114712009984\n",
      "1719633093551589888\n",
      "1719615580923699968\n",
      "1719647797592920064\n",
      "1719643260876809984\n",
      "1719625650296930048\n",
      "1719584090217449984\n",
      "1719609661848339968\n",
      "1719591848164219904\n",
      "1719645691541900032\n",
      "1719581548905240064\n",
      "1719587666509029888\n",
      "1719644362683059968\n",
      "1719633190728770048\n",
      "1719648566525890048\n",
      "1719645028330840064\n",
      "1719497737007569920\n",
      "1719589722667130112\n",
      "1719615001099360000\n",
      "1719601991767709952\n",
      "1719636524205050112\n",
      "1719585436833570048\n",
      "1719618594615190016\n",
      "1719587311619950080\n",
      "1719616865352160000\n",
      "1719642867225159936\n",
      "1719648438445360128\n",
      "1719639598237270016\n",
      "1719616156451490048\n",
      "1719660611382020096\n",
      "1719592201192839936\n",
      "1719480993554949888\n",
      "1719541134574850048\n",
      "1719621751802959872\n",
      "1719603738244930048\n",
      "1719637917472790016\n",
      "1719542393285479936\n",
      "1719631039053299968\n",
      "1719633034105560064\n",
      "1719647326174889984\n",
      "1719623630459059968\n",
      "1719594252393979904\n",
      "1719658208327600128\n",
      "1719585760333799936\n",
      "1719632027141769984\n",
      "1719593146776620032\n",
      "1719604312224039936\n",
      "1719621293069600000\n",
      "1719620759529609984\n",
      "1719591674867160064\n",
      "1719638356229329920\n",
      "1719645797107140096\n",
      "1719571191511800064\n",
      "1719589027842400000\n",
      "1719643052967219968\n",
      "1719650033455780096\n",
      "1719637754896600064\n",
      "1719533120701070080\n",
      "1719622141116450048\n",
      "1719646144096819968\n",
      "1719623492044310016\n",
      "1719613919723670016\n",
      "1719519550860809984\n",
      "1719594425980310016\n",
      "1719612005136079872\n",
      "1719621883737530112\n",
      "1719618941688859904\n",
      "1719587286468859904\n",
      "1719587423152869888\n",
      "1719599394643790080\n",
      "1719642975502080000\n",
      "1719642453460369920\n",
      "1719650778125060096\n",
      "1719590912774660096\n",
      "1719531332111749888\n",
      "1719518169136730112\n",
      "1719595890000519936\n",
      "1719661985533479936\n",
      "1719621063043130112\n",
      "1719586593820590080\n",
      "1719625261848339968\n",
      "1719649889905430016\n",
      "1719625469726040064\n",
      "1719654749170340096\n",
      "1719640539845609984\n",
      "1719643935306899968\n",
      "1719595742907899904\n",
      "1719654753911719936\n",
      "1719654576031369984\n",
      "1719612174887899904\n",
      "1719651371575280128\n",
      "1719595290939840000\n",
      "1719634092114269952\n",
      "1719615155576950016\n",
      "1719603032917199872\n",
      "1719607776327320064\n",
      "1719625388930259968\n",
      "1719642545149920000\n",
      "1719615312447790080\n",
      "1719617051667340032\n",
      "1719615536900410112\n",
      "1719632435184290048\n",
      "1719603123112649984\n",
      "1719634355207249920\n",
      "1719634162105420032\n",
      "1719646683387269888\n",
      "1719615846199869952\n",
      "1719582831197700096\n",
      "1719606187051899904\n",
      "1719604634413700096\n",
      "1719621588939180032\n",
      "1719619889104290048\n",
      "1719645229777200128\n",
      "1719627515940130048\n",
      "1719620566446510080\n",
      "1719525040746299904\n",
      "1719614146320950016\n",
      "1719618412257560064\n",
      "1719479424360960000\n",
      "1719635051601760000\n",
      "1719615840595239936\n",
      "1719600356607680000\n",
      "1719616028422380032\n",
      "1719591999746660096\n",
      "1719593026813730048\n",
      "1719586128480819968\n",
      "1719606036963049984\n",
      "1719637059198569984\n",
      "1719638011642530048\n",
      "1719584199357129984\n",
      "1719592230605360128\n",
      "1719492900261730048\n",
      "1719523044353230080\n",
      "1719642229071150080\n",
      "1719648448878870016\n",
      "1719607049427239936\n",
      "1719621462138409984\n",
      "1719593589277969920\n",
      "1719649246710569984\n",
      "1719610990798129920\n",
      "1719612747985019904\n",
      "1719655963050970112\n",
      "1719636592665829888\n",
      "1719635171061220096\n",
      "1719618000283950080\n",
      "1719623837847280128\n",
      "1719591801444049920\n",
      "1719613660103460096\n",
      "1719594313265479936\n",
      "1719322241360189952\n",
      "1719570464211099904\n",
      "1719640336589169920\n",
      "1719567788968100096\n",
      "1719645206648329984\n",
      "1719615825942350080\n",
      "1719635161289299968\n",
      "1719629642386609920\n",
      "1719492268347889920\n",
      "1719597149789949952\n",
      "1719659542516989952\n",
      "1719607843258190080\n",
      "1719640370445029888\n",
      "1719619004850589952\n",
      "1719598142023899904\n",
      "1719590753669159936\n",
      "1719588963179630080\n",
      "1719640487177260032\n",
      "1719621220581870080\n",
      "1719612939307899904\n",
      "1719659332625629952\n",
      "1719617300163739904\n",
      "1719611692412920064\n",
      "1719570134631079936\n",
      "1719502726761929984\n",
      "1719491201677659904\n",
      "1719647092784890112\n",
      "1719646512864219904\n",
      "1719620229771840000\n",
      "1719603749176790016\n",
      "1719608896175300096\n",
      "1719583211199660032\n",
      "1719577264797829888\n",
      "1719611173749410048\n",
      "1719579508607869952\n",
      "1719610981012529920\n",
      "1719584986465359872\n",
      "1719593476151889920\n",
      "1719624621847879936\n",
      "1012174178542860032\n",
      "1719687442434180096\n",
      "1719665049390990080\n",
      "1719673742249939968\n",
      "1719668435449829888\n",
      "1719662516146589952\n",
      "1719673545069609984\n",
      "1719679602280009984\n",
      "1719669562763429888\n",
      "1719661930319239936\n",
      "1719672882406970112\n",
      "1719686334212130048\n",
      "1719670155033090048\n",
      "1719683082820029952\n",
      "1719433141116229888\n",
      "1719604862263379968\n",
      "1719664613596960000\n",
      "1719585713023569920\n",
      "1719654749717499904\n",
      "1719670488912580096\n",
      "1719675817739059968\n",
      "1719548796401390080\n",
      "1719683535955300096\n",
      "1719665522376689920\n",
      "1719660143345799936\n",
      "1719686700364910080\n",
      "1719551923108529920\n",
      "1719672343838230016\n",
      "1719670398743610112\n",
      "1719555614617920000\n",
      "1719566775319889920\n",
      "1719654088260930048\n",
      "1719591918564869888\n",
      "1719664031646949888\n",
      "1719667428603960064\n",
      "1719680852245250048\n",
      "1719671904789220096\n",
      "1719661815690040064\n",
      "1539560147437410048\n",
      "1719672349337750016\n",
      "1719552864313410048\n",
      "1719547382078710016\n",
      "1719552708374200064\n",
      "1719651651347930112\n",
      "1719684546620740096\n",
      "1500672904671229952\n",
      "1719599816498889984\n",
      "1719671718212930048\n",
      "1719666758224150016\n",
      "1719670585860969984\n",
      "1719671621181410048\n",
      "1719564806645449984\n",
      "1719596893349959936\n",
      "1719550445140780032\n",
      "1719604457430850048\n",
      "1719685476279830016\n",
      "1719673296044049920\n",
      "1719667010131859968\n",
      "1719666098850210048\n",
      "1719673106678550016\n",
      "1719669038208930048\n",
      "1719667191054220032\n",
      "1719627183642729984\n",
      "1719628833778390016\n",
      "1719605796362340096\n",
      "1719677256189050112\n",
      "1719681319242619904\n",
      "1717124382061519872\n",
      "1717123342644400128\n",
      "1712255182126089984\n",
      "1717086104618589952\n",
      "1717123276155079936\n",
      "1558447242433430016\n",
      "1713514822520719872\n",
      "1449559553293910016\n",
      "1717120477937100032\n",
      "1714890743142500096\n",
      "1562375301256940032\n",
      "1716975941799369984\n",
      "1717120476488539904\n",
      "1717119492667249920\n",
      "1717118773654099968\n",
      "1717120645857609984\n",
      "1717120069997060096\n",
      "1717050730760570112\n",
      "1712881286238249984\n",
      "1717127937481900032\n",
      "1717128267512669952\n",
      "1717129105812379904\n",
      "1717127790081050112\n",
      "1717128567028270080\n",
      "1717128592861420032\n",
      "1717128949069829888\n",
      "1415592266290139904\n",
      "1506832281178800128\n",
      "1560464046806139904\n",
      "1469671657569039872\n",
      "1717129399490449920\n",
      "1717129779690070016\n",
      "1717129311649619968\n",
      "1717129723959099904\n",
      "1717131026070919936\n",
      "1716823555385200128\n",
      "1717093801248539904\n",
      "1717028333003719936\n",
      "1717112353358240000\n",
      "1717118084222880000\n",
      "1717043162640950016\n",
      "1717006866071130112\n",
      "1717083733811699968\n",
      "1717137392393359872\n",
      "1717084001387830016\n",
      "1717140013123559936\n",
      "1716742026811120128\n",
      "1717099664694370048\n",
      "1717137509776969984\n",
      "1717136821476790016\n",
      "1717034858871620096\n",
      "1716431835045040128\n",
      "1717002774874609920\n",
      "1716010357048590080\n",
      "1717120904016910080\n",
      "1716943150020630016\n",
      "1717132758388869888\n",
      "1717135426739790080\n",
      "1717120036537829888\n",
      "1717135241963830016\n",
      "1717085016494870016\n",
      "1716624532877230080\n",
      "1716807172860169984\n",
      "1716936163107000064\n",
      "1717096974401380096\n",
      "1717068636090319872\n",
      "1716944088098739968\n",
      "1716996246171879936\n",
      "1717002482038769920\n",
      "1717005812804699904\n",
      "1716696361492549888\n",
      "1717081047964090112\n",
      "1716988597647579904\n",
      "1717120053152369920\n",
      "1716964403056280064\n",
      "1717051047859470080\n",
      "1717096982052669952\n",
      "1716781561708890112\n",
      "1717016991710880000\n",
      "1716795837310850048\n",
      "1716714810643879936\n",
      "1717131473244509952\n",
      "1717139581234660096\n",
      "1717140340580910080\n",
      "1717133939804590080\n",
      "1717092090272989952\n",
      "1716880067168150016\n",
      "1717048519038490112\n",
      "1717128785724559872\n",
      "1717114433098800128\n",
      "1717044686692090112\n",
      "1717076699705090048\n",
      "1716970511250299904\n",
      "1717131937032659968\n",
      "1716838790988290048\n",
      "1717101321633359872\n",
      "1717020474264489984\n",
      "1717136683549280000\n",
      "1717075300931650048\n",
      "1717125429139919872\n",
      "1717087643894530048\n",
      "1717036165284110080\n",
      "1716990245572839936\n",
      "1716094507214619904\n",
      "1717016132557590016\n",
      "1717130328814080000\n",
      "1717107916081469952\n",
      "1716857754951780096\n",
      "1717113847448839936\n",
      "1717140890599000064\n",
      "1716645605699559936\n",
      "1717133742779010048\n",
      "1717139743810129920\n",
      "1717136232835010048\n",
      "1717018748881520128\n",
      "1717092156156450048\n",
      "1717081885507970048\n",
      "1717028823467919872\n",
      "1717042031022870016\n",
      "1717137682751579904\n",
      "1717132896274860032\n",
      "1717134885973380096\n",
      "1716359373310530048\n",
      "1717139516650050048\n",
      "1717121234869819904\n",
      "1717063954053009920\n",
      "1717069495077540096\n",
      "1717104318486220032\n",
      "1717134406331239936\n",
      "1716990340602579968\n",
      "1717106120845760000\n",
      "1717050706961029888\n",
      "1717137533880910080\n",
      "1717133338511040000\n",
      "1716655543117159936\n",
      "1717093173869580032\n",
      "1717129141363130112\n",
      "1717140891898629888\n",
      "1716996750830949888\n",
      "1716985783954170112\n",
      "1716654142704290048\n",
      "1717058498460979968\n",
      "1717137509072179968\n",
      "1717084587239310080\n",
      "1716701680162279936\n",
      "1716803419707719936\n",
      "1716739164496430080\n",
      "1716991537495630080\n",
      "1717040323586540032\n",
      "1717134772069619968\n",
      "1717140589990070016\n",
      "1716990795303000064\n",
      "1717046212282550016\n",
      "1717027716698840064\n",
      "1717054403350520064\n",
      "1717012883234390016\n",
      "1717026037825920000\n",
      "1717082552154119936\n",
      "1716809154418449920\n",
      "1716340786351579904\n",
      "1717136520077250048\n",
      "1717017615886490112\n",
      "1716992187043419904\n",
      "1717002639130070016\n",
      "1717120531063280128\n",
      "1717134271167010048\n",
      "1717059187349669888\n",
      "1716674811040880128\n",
      "1717036398386710016\n",
      "1717001910510769920\n",
      "1717114367884989952\n",
      "1717087679069250048\n",
      "1717121143335490048\n",
      "1717018096045410048\n",
      "1717068113499079936\n",
      "1717006828691970048\n",
      "1717076074928560128\n",
      "1717140809634119936\n",
      "1717034759528890112\n",
      "1716991148589319936\n",
      "1717082371466149888\n",
      "1717081456117880064\n",
      "1717132273383439872\n",
      "1717125662042720000\n",
      "1717082548143429888\n",
      "1717005485231709952\n",
      "1717072373750939904\n",
      "1716806839937289984\n",
      "1717139811013100032\n",
      "1717130106304290048\n",
      "1717003411933090048\n",
      "1717135651483290112\n",
      "1717029251153200128\n",
      "1716798261333349888\n",
      "1717020682767539968\n",
      "1716727171214139904\n",
      "1717017188956770048\n",
      "1716970033259290112\n",
      "1717137014039470080\n",
      "1717075938737750016\n",
      "1717097563386510080\n",
      "1716801190898850048\n",
      "1716816752257730048\n",
      "1717102037978670080\n",
      "1717127222039369984\n",
      "1717138552472560128\n",
      "1716248641697370112\n",
      "1717127680500290048\n",
      "1717089890571950080\n",
      "1717134726679600128\n",
      "1717007651534249984\n",
      "1717013837605299968\n",
      "1717013510034970112\n",
      "1717098876247790080\n",
      "1717049931736209920\n",
      "1717043231302619904\n",
      "1716365436569440000\n",
      "1717133050343840000\n",
      "1717142460278919936\n",
      "1716990549277710080\n",
      "1717149571748659968\n",
      "1717148640110060032\n",
      "1716361260024389888\n",
      "1717035331259500032\n",
      "1717131267622899968\n",
      "1716988586933420032\n",
      "1717085920692659968\n",
      "1716989425842889984\n",
      "1717007618756610048\n",
      "1717085173541050112\n",
      "1716986758127460096\n",
      "1716956833468470016\n",
      "1717015250055480064\n",
      "1717000679787780096\n",
      "1717067143891460096\n",
      "1716846383188920064\n",
      "1717011681403520000\n",
      "1717031757955500032\n",
      "1717001651311069952\n",
      "1717151072065929984\n",
      "1717076672724509952\n",
      "1717149905304839936\n",
      "1717073008562569984\n",
      "1716457082795790080\n",
      "1717056217504440064\n",
      "1717149028426390016\n",
      "1716767707258429952\n",
      "1717139607481060096\n",
      "1717145007695170048\n",
      "1717141847686040064\n",
      "1716737439509210112\n",
      "1717141940902660096\n",
      "1717147179086340096\n",
      "1717147734290569984\n",
      "1716243570444140032\n",
      "1716985761225230080\n",
      "1717062082497090048\n",
      "1717059135928079872\n",
      "1717056609382449920\n",
      "1716847128915200000\n",
      "1717115623009550080\n",
      "1717028301719429888\n",
      "1717007266302170112\n",
      "1716818273141459968\n",
      "1717083437622220032\n",
      "1717036734757309952\n",
      "1717093262737200128\n",
      "1717111497854259968\n",
      "1717004181085479936\n",
      "1717020919917680128\n",
      "1717137190850350080\n",
      "1717007049644179968\n",
      "1716656561691300096\n",
      "1716045449266909952\n",
      "1716990795902880000\n",
      "1716984420707460096\n",
      "1716335607959000064\n",
      "1716997079901199872\n",
      "1717141446195020032\n",
      "1717003830159729920\n",
      "1716991288332999936\n",
      "1717098143404229888\n",
      "1716624235824039936\n",
      "1717094966729019904\n",
      "1716649216171279872\n",
      "1717037953389560064\n",
      "1716997062110840064\n",
      "1717013891555599872\n",
      "1717131394774089984\n",
      "1716775402552169984\n",
      "1716456433626579968\n",
      "1716682678833760000\n",
      "1716991017840140032\n",
      "1716990026862510080\n",
      "1717107254083899904\n",
      "1717033079621929984\n",
      "1717115813447729920\n",
      "1717075312894820096\n",
      "1717050781356689920\n",
      "1717097199169929984\n",
      "1716991548830779904\n",
      "1716248306341789952\n",
      "1717002182192519936\n",
      "1716285505460640000\n",
      "1717136439637920000\n",
      "1716991752514360064\n",
      "1717031788191729920\n",
      "1716399270179379968\n",
      "1717014258959849984\n",
      "1716990418438540032\n",
      "1715992732654109952\n",
      "1716998846590060032\n",
      "1717088645680910080\n",
      "1717129402376130048\n",
      "1716972984085669888\n",
      "1717013221823859968\n",
      "1717075608316430080\n",
      "1716990108947190016\n",
      "1716843461410160128\n",
      "1717083654180740096\n",
      "1717135785888539904\n",
      "1717097392107919872\n",
      "1716284964538030080\n",
      "1717004679145570048\n",
      "1717032464778249984\n",
      "1717114873421440000\n",
      "1717105214887369984\n",
      "1717076426977100032\n",
      "1717126440367030016\n",
      "1716241912389639936\n",
      "1717034585376410112\n",
      "1717086968526259968\n",
      "1716402497335600128\n",
      "1716248951866149888\n",
      "1716396886084420096\n",
      "1716841607641039872\n",
      "1717136865158449920\n",
      "1716263244150020096\n",
      "1716734207507089920\n",
      "1716324727322579968\n",
      "1717014472512839936\n",
      "1717113708109570048\n",
      "1716973276864859904\n",
      "1716397815911290112\n",
      "1716844690123130112\n",
      "1716967382289910016\n",
      "1716670701217649920\n",
      "1716351521727709952\n",
      "1716732615324130048\n",
      "1716244962911130112\n",
      "1717083082832809984\n",
      "1716846602880950016\n",
      "1716741535685989888\n",
      "1717125660432800000\n",
      "1716999257542510080\n",
      "1716736043634970112\n",
      "1716790802602919936\n",
      "1716820826896880128\n",
      "1716744418699559936\n",
      "1716311296978589952\n",
      "1717047003821530112\n",
      "1717521534853649920\n",
      "1717540305739859968\n",
      "1717521617701339904\n",
      "1717482169091709952\n",
      "1717382891425929984\n",
      "1717312101185570048\n",
      "1717398218354170112\n",
      "1717485703740329984\n",
      "1717331277612420096\n",
      "1717448789127170048\n",
      "1717507897156389888\n",
      "1717358003801679872\n",
      "1717525459592859904\n",
      "1717455385479749888\n",
      "1717520023254320128\n",
      "1717348749402639872\n",
      "1717338185726810112\n",
      "1717524517242639872\n",
      "1717528711116489984\n",
      "1717458697140689920\n",
      "1717529306496669952\n",
      "1717347693776179968\n",
      "1717508796226870016\n",
      "1717499295336320000\n",
      "1717524876169289984\n",
      "1717450750027209984\n",
      "1717457116063719936\n",
      "1717532375827419904\n",
      "1717526197070449920\n",
      "1717511366694249984\n",
      "1717529644772760064\n",
      "1717424863687529984\n",
      "1717533446785600000\n",
      "1717513472482299904\n",
      "1717535101609189888\n",
      "1717519383246380032\n",
      "1717367779399539968\n",
      "1717516687232780032\n",
      "1717516339153570048\n",
      "1717484090770510080\n",
      "1717481038465220096\n",
      "1717410603659450112\n",
      "1717524275649959936\n",
      "1717379244651089920\n",
      "1717548786272470016\n",
      "1717518038247739904\n",
      "1717425297333029888\n",
      "1717355558060529920\n",
      "1717534308821669888\n",
      "1717165551633139968\n",
      "1717508153592389888\n",
      "1717525011657890048\n",
      "1717460721121829888\n",
      "1717349569565459968\n",
      "1717399783025690112\n",
      "1717518075069139968\n",
      "1717419410996940032\n",
      "1717532998292869888\n",
      "1717427623833339904\n",
      "1717547648485530112\n",
      "1717383385664839936\n",
      "1717529141808600064\n",
      "1717511171515749888\n",
      "1717526209046020096\n",
      "1717475299231290112\n",
      "1717472216107470080\n",
      "1717529659504480000\n",
      "1717426753334909952\n",
      "1717428956640549888\n",
      "1717426522442670080\n",
      "1717426133936869888\n",
      "1717423926495650048\n",
      "1717514316597829888\n",
      "1717428404984709888\n",
      "1717424323557819904\n",
      "1717383415009349888\n",
      "1717474040425710080\n",
      "1717472938053570048\n",
      "1717384291233009920\n",
      "1717471605233779968\n",
      "1717379834231360000\n",
      "1717419953072079872\n",
      "1717409292967450112\n",
      "1717380097138729984\n",
      "1717408552530190080\n",
      "1717418546398990080\n",
      "1717384455494540032\n",
      "1717410075855259904\n",
      "1717383879398490112\n",
      "1717473825018840064\n",
      "1717416623784560128\n",
      "1717459017670299904\n",
      "1717458259822479872\n",
      "1717375546239190016\n",
      "1717383654877400064\n",
      "1717384086538390016\n",
      "1717471098645750016\n",
      "1717530652615739904\n",
      "1717401943632120064\n",
      "1705477306275909888\n",
      "1701472133955820032\n",
      "1643856793117969920\n",
      "1717354670193479936\n",
      "1527913011317230080\n",
      "1717550861046129920\n",
      "1717518258963810048\n",
      "1717460796100679936\n",
      "1717548204602200064\n",
      "1717540067928219904\n",
      "1717470556333299968\n",
      "1717537721181750016\n",
      "1717419749690279936\n",
      "1717541868334210048\n",
      "1717539194277479936\n",
      "1717541479797850112\n",
      "1717534591317959936\n",
      "1717499425995170048\n",
      "1717523895893329920\n",
      "1717476812584329984\n",
      "1717548768302210048\n",
      "1717549003617110016\n",
      "1717522340154820096\n",
      "1717544478469740032\n",
      "1717517790222749952\n",
      "1717558843148489984\n",
      "1717601686476740096\n",
      "1717179000122070016\n",
      "1717680085681840128\n",
      "1717459406198540032\n",
      "1717558247657979904\n",
      "1717479326631350016\n",
      "1717607300757509888\n",
      "1717539198803219968\n",
      "1717579074873179904\n",
      "1717555652671930112\n",
      "1717527643521110016\n",
      "1717437997537920000\n",
      "1717564893243249920\n",
      "1717567052169449984\n",
      "1717528011407460096\n",
      "1717460739348470016\n",
      "1717530300662779904\n",
      "1717473720903340032\n",
      "1717706855342050048\n",
      "1717697593596989952\n",
      "1717507766046769920\n",
      "1717716287675190016\n",
      "1717596200575699968\n",
      "1717476930761019904\n",
      "1717531570928509952\n",
      "1717531286965740032\n",
      "1717481262407500032\n",
      "1717531085739810048\n",
      "1717476709138190080\n",
      "1717706592178899968\n",
      "1717713707199140096\n",
      "1717588616731709952\n",
      "1717588242931140096\n",
      "1717709304534569984\n",
      "1717473069066560000\n",
      "1717552478692150016\n",
      "1717721665580720128\n",
      "1717716758196410112\n",
      "1717715222621390080\n",
      "1717481628377309952\n",
      "1717609291512600064\n",
      "1717538251271539968\n",
      "1717534033811440128\n",
      "1717592813793679872\n",
      "1717422149018520064\n",
      "1717587178815249920\n",
      "1717591412585760000\n",
      "1717592434129479936\n",
      "1717758710419429888\n",
      "1717804435842899968\n",
      "1717697461132529920\n",
      "1717686418072560128\n",
      "1717724840559239936\n",
      "1717769510196480000\n",
      "1717661304727200000\n",
      "1519579266249029888\n",
      "1717744462656930048\n",
      "1717808862070810112\n",
      "1717722577692920064\n",
      "1717738793009750016\n",
      "1717776924168800000\n",
      "1717765615464630016\n",
      "1717812716968219904\n",
      "1717814646987689984\n",
      "1717792183868920064\n",
      "1717795682662929920\n",
      "1717806581399409920\n",
      "1717721484579099904\n",
      "1717778317505039872\n",
      "1717650794206700032\n",
      "1717781271564600064\n",
      "1717766257583350016\n",
      "1717695535580649984\n",
      "1717722531098269952\n",
      "1717769755750860032\n",
      "1717735778307919872\n",
      "1717800385674990080\n",
      "1717699756854500096\n",
      "1717731318038830080\n",
      "1717723489931239936\n",
      "1717721533243670016\n",
      "1717799975614710016\n",
      "1717579736656740096\n",
      "1717089201699020032\n",
      "1717728844431399936\n",
      "1717534699172839936\n",
      "1717749534147350016\n",
      "1717763077441720064\n",
      "1717747914500219904\n",
      "1717789047171440128\n",
      "1717715237280489984\n",
      "1717823776156160000\n",
      "1717805652983529984\n",
      "1717752799460950016\n",
      "1717771710849750016\n",
      "1717728701865479936\n",
      "1716988740805530112\n",
      "1717796989357769984\n",
      "1717731383216100096\n",
      "1717761592064610048\n",
      "1717717501896910080\n",
      "1717744442408460032\n",
      "1717806116155719936\n",
      "1717770784791830016\n",
      "1717781071369690112\n",
      "1717757804945629952\n",
      "1717614365157100032\n",
      "1717575057070459904\n",
      "1717724512897520128\n",
      "1717577245401400064\n",
      "1717753986486000128\n",
      "1717780954957989888\n",
      "1717805150547640064\n",
      "1717784003435419904\n",
      "1717696533609210112\n",
      "1717765346579650048\n",
      "1717795600323450112\n",
      "1717737107915300096\n",
      "1717773576438929920\n",
      "1717576521089700096\n",
      "1717780910655930112\n",
      "1717507725258690048\n",
      "1717433913063820032\n",
      "1717708714731389952\n",
      "1717773295493570048\n",
      "1717801624049489920\n",
      "1717564463124090112\n",
      "1717783326710070016\n",
      "1717802478223069952\n",
      "1717813712808560128\n",
      "1717792518490030080\n",
      "1717780250064900096\n",
      "1717776831732720128\n",
      "1717673202839569920\n",
      "1717737311139830016\n",
      "1717803401453360128\n",
      "1717782886624300032\n",
      "1717812843071739904\n",
      "1717775414871790080\n",
      "1717803366148539904\n",
      "1717762046011689984\n",
      "1717788541207069952\n",
      "1717799440373669888\n",
      "1717735085122880000\n",
      "1717801457320989952\n",
      "1717738069187069952\n",
      "1717797076159780096\n",
      "1717804306473649920\n",
      "1717737140524669952\n",
      "1717798336976509952\n",
      "1717716193159040000\n",
      "1717738924865949952\n",
      "1717807379151920128\n",
      "1717813680047529984\n",
      "1717742280221989888\n",
      "1717764204746560000\n",
      "1717781866225959936\n",
      "1717787576814279936\n",
      "1717753551415040000\n",
      "1717771975596430080\n",
      "1717784238496649984\n",
      "1717780680822510080\n",
      "1717764275262129920\n",
      "1717803141653530112\n",
      "1717805709800359936\n",
      "1717698739574390016\n",
      "1717805617872410112\n",
      "1717781481908470016\n",
      "1717792866013750016\n",
      "1717690785435569920\n",
      "1717769220479830016\n",
      "1717799588483269888\n",
      "1717806264369840128\n",
      "1717779399016189952\n",
      "1717742523872300032\n",
      "1717687211938899968\n",
      "1717734327054210048\n",
      "1717768344558159872\n",
      "1717783288591419904\n",
      "1717803796683000064\n",
      "1717782088852709888\n",
      "1717743321767529984\n",
      "1717688740565570048\n",
      "1717778198119109888\n",
      "1717753448985649920\n",
      "1717782835468179968\n",
      "1717769775637910016\n",
      "1717806123964420096\n",
      "1717736802589329920\n",
      "1717807104346939904\n",
      "1717816583794690048\n",
      "1717544074427950080\n",
      "1717806962376430080\n",
      "1717773990451069952\n",
      "1717818484032509952\n",
      "1717770069314690048\n",
      "1717807621888790016\n",
      "1717820021962149888\n",
      "1717755657290899968\n",
      "1717771464586880000\n",
      "1717802781791460096\n",
      "1717808912476130048\n",
      "1717772330727229952\n",
      "1717808150383680000\n",
      "1717745997439689984\n",
      "1717779802762370048\n",
      "1717808578699320064\n",
      "1717783959514759936\n",
      "1717778122234779904\n",
      "1717781573018700032\n",
      "1717776192108349952\n",
      "1717747930934139904\n",
      "1717789223399840000\n",
      "1717769985159190016\n",
      "1717794288469230080\n",
      "1717749217202279936\n",
      "1717835965559160064\n",
      "1717074754139620096\n",
      "1717854101392069888\n",
      "1717716371916000000\n",
      "1717729067213900032\n",
      "1717840098390840064\n",
      "1717720067839330048\n",
      "1717727043857139968\n",
      "1717711776729289984\n",
      "1717827921724430080\n",
      "1717858561571379968\n",
      "1717856470544730112\n",
      "1717843032512730112\n",
      "1717732737930759936\n",
      "1717862487687470080\n",
      "1717727226831379968\n",
      "1717713562316669952\n",
      "1717847089681679872\n",
      "1717720447515399936\n",
      "1717824648533900032\n",
      "1717743954121530112\n",
      "1717839282982360064\n",
      "1717863625076659968\n",
      "1717831036868300032\n",
      "1717714881267780096\n",
      "1717848590644839936\n",
      "1717859294058040064\n",
      "1717729485713380096\n",
      "1717728392032590080\n",
      "1717841152889440000\n",
      "1717718058888839936\n",
      "1717859422837260032\n",
      "1717848086541979904\n",
      "1717855814453139968\n",
      "1717826439880989952\n",
      "1717713541876059904\n",
      "1717860382232880128\n",
      "1717823522207140096\n",
      "1717834209750010112\n",
      "1717856652181769984\n",
      "1717871710115980032\n",
      "1717769223145900032\n",
      "1717848172388260096\n",
      "1717831368345750016\n",
      "1717841617981949952\n",
      "1717864939976410112\n",
      "1717716631318240000\n",
      "1717853717522400000\n",
      "1717762015115909888\n",
      "1717835604066909952\n",
      "1717733915131630080\n",
      "1717830852522959872\n",
      "1717761893518960128\n",
      "1717750345964999936\n",
      "1717847942029969920\n",
      "1717860718460869888\n",
      "1717669051674370048\n",
      "1717853138250139904\n",
      "1717873880038360064\n",
      "1421644750926350080\n",
      "1718128995674949888\n",
      "1309132874270960128\n",
      "1704375591104069888\n",
      "1703782558918690048\n",
      "1718128577511229952\n",
      "1718126959059569920\n",
      "1717866522874449920\n",
      "1718123932130050048\n",
      "1718139243828659968\n",
      "1718106217410840064\n",
      "1718132703031970048\n",
      "1717894278936699904\n",
      "1718141482482860032\n",
      "1718054390720679936\n",
      "1718115777114390016\n",
      "1718109168549420032\n",
      "1718108973052910080\n",
      "1718110237614589952\n",
      "1718093744821179904\n",
      "1718113989204239872\n",
      "1718144803498540032\n",
      "1718122994260910080\n",
      "1718076496567739904\n",
      "1718144490206990080\n",
      "1718135359742909952\n",
      "1717918546099889920\n",
      "1718132903984389888\n",
      "1718101357514490112\n",
      "1718129336239770112\n",
      "1718065761016270080\n",
      "1718134070149370112\n",
      "1718130242110129920\n",
      "1718130668061789952\n",
      "1718110922420430080\n",
      "1718147381549210112\n",
      "1718140763396130048\n",
      "1718148390821580032\n",
      "1718139402134640128\n",
      "1717922336039419904\n",
      "1718132676791520000\n",
      "1718134199834739968\n",
      "1718138439154599936\n",
      "1718145763972760064\n",
      "1717920778200499968\n",
      "1718135789115889920\n",
      "1717900603454609920\n",
      "1718140323001080064\n",
      "1718144999374520064\n",
      "1717873380966449920\n",
      "1718129745378200064\n",
      "1718144179383899904\n",
      "1718148527708720128\n",
      "1718138832316849920\n",
      "1718134259455940096\n",
      "1718152181798949888\n",
      "1718146355170710016\n",
      "1718145333186599936\n",
      "1718143999796379904\n",
      "1718217176421390080\n",
      "1718202345255620096\n",
      "1718146372532199936\n",
      "1718174210028080128\n",
      "1718196961795279872\n",
      "1718204207668280064\n",
      "1718184724701730048\n",
      "1718198046132969984\n",
      "1718193457931620096\n",
      "1718191809908410112\n",
      "1718163569181860096\n",
      "1718185257010779904\n",
      "1718192612443940096\n",
      "1718213268245220096\n",
      "1718084164636009984\n",
      "1718105862589550080\n",
      "1718069862743940096\n",
      "1718202227691379968\n",
      "1718179165919269888\n",
      "1718196494454099968\n",
      "1718080907549120000\n",
      "1718177106933649920\n",
      "1718208246019030016\n",
      "1718093616256389888\n",
      "1718182014240329984\n",
      "1718196758665009920\n",
      "1718209259901949952\n",
      "1718136776980809984\n",
      "1718172676393230080\n",
      "1718189640969200128\n",
      "1718138987387930112\n",
      "1718193633015759872\n",
      "1718198285874550016\n",
      "1718178007547480064\n",
      "1718191356779909888\n",
      "1717967557076090112\n",
      "1718178504573370112\n",
      "1718200538617890048\n",
      "1718069355350599936\n",
      "1718138710089260032\n",
      "1718153362838149888\n",
      "1718194002228519936\n",
      "1718185243738850048\n",
      "1718090819837959936\n",
      "1718195440324280064\n",
      "1718173444217309952\n",
      "1718209569150619904\n",
      "1718174937801499904\n",
      "1718084154450639872\n",
      "1718198867270259968\n",
      "1718193545442870016\n",
      "1718180660180649984\n",
      "1718184538245710080\n",
      "1718187635901669888\n",
      "1718209183299820032\n",
      "1718180850114510080\n",
      "1718082769694769920\n",
      "1718179324267529984\n",
      "1718207759953890048\n",
      "1718183257679569920\n",
      "1718188510309189888\n",
      "1718204740098350080\n",
      "1718148802297220096\n",
      "1718179275900950016\n",
      "1718179699214899968\n",
      "1718176324956430080\n",
      "1718242511897710080\n",
      "1573501835873410048\n",
      "1718236707745220096\n",
      "1718223235889829888\n",
      "1718244246907249920\n",
      "1718249335686860032\n",
      "1718077652761629952\n",
      "1718205554497979904\n",
      "1718242855282449920\n",
      "1718141768781710080\n",
      "1718239745928480000\n",
      "1718247867572570112\n",
      "1718254868030510080\n",
      "1718244464249050112\n",
      "1718244744128649984\n",
      "1718245463429469952\n",
      "1718058390363640064\n",
      "1718238335215960064\n",
      "1718229198935200000\n",
      "1718113681205760000\n",
      "1718188187830129920\n",
      "1718248802853430016\n",
      "1718226675967960064\n",
      "1718134035025870080\n",
      "1718242272323460096\n",
      "1718246980654830080\n",
      "1718429189507450112\n",
      "1718446189068800000\n",
      "1718123777508969984\n",
      "1718214621813080064\n",
      "1718432205763729920\n",
      "1718441475811500032\n",
      "1718441882572610048\n",
      "1718284213368049920\n",
      "1718453209269799936\n",
      "1718232184494220032\n",
      "1718225502516780032\n",
      "1718430447374500096\n",
      "1718181970123660032\n",
      "1718284326456839936\n",
      "1718428910621280000\n",
      "1718429260567290112\n",
      "1718441605960849920\n",
      "1718566068366889984\n",
      "1718560500255439872\n",
      "1718557067792930048\n",
      "1718546709125189888\n",
      "1718555125099930112\n",
      "1718422741863219968\n",
      "1718547552635460096\n",
      "1718311201453380096\n",
      "1718544664786739968\n",
      "1718553375160310016\n",
      "1718548646269410048\n",
      "1718555221641349888\n",
      "1718549196734939904\n",
      "1718556019860590080\n",
      "1718545625713479936\n",
      "1718567141705900032\n",
      "1718555217566990080\n",
      "1700189583517080064\n",
      "1696510121692809984\n",
      "1718544900559689984\n",
      "1718560845065339904\n",
      "1718550796456009984\n",
      "1718544054597929984\n",
      "1718510088707770112\n",
      "1718550500481319936\n",
      "1718555761147529984\n",
      "1718563052376539904\n",
      "1718618820372879872\n",
      "1718596591663960064\n",
      "1718596983101580032\n",
      "1718597236626279936\n",
      "1718569594980130048\n"
     ]
    }
   ],
   "source": [
    "for row in data[data.index>=3424][['infoId','所有图片链接']].itertuples(index=False):\n",
    "    id,urls = row\n",
    "    print(id)\n",
    "    if \"|\" in str(urls):\n",
    "        urls = urls.split('|')\n",
    "        for i in range(len(urls)):\n",
    "            urlretrieve(urls[i],f'D:/paper/二手产品/picture/{i}_{id}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像分析 clarifai API 先清洗数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\n",
    "from clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\n",
    "from clarifai_grpc.grpc.api.status import status_code_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################################################################\n",
    "# In this section, we set the user authentication, user and app ID, model details, and the URL\n",
    "# of the image we want as an input. Change these strings to run your own example.\n",
    "#################################################################################################\n",
    "\n",
    "# Your PAT (Personal Access Token) can be found in the portal under Authentification\n",
    "PAT = 'b63e70c1142b40409aece3b02406b3fc'\n",
    "# Specify the correct user_id/app_id pairings\n",
    "# Since you're making inferences outside your app's scope\n",
    "USER_ID = 'hrainting'\n",
    "APP_ID = 'main'\n",
    "# Change these to whatever model and image URL you want to use\n",
    "MODEL_ID = 'food-item-recognition'\n",
    "MODEL_VERSION_ID = '1d5fd481e0cf4826aa72ec3ff049e044'\n",
    "IMAGE_URL = 'https://samples.clarifai.com/metro-north.jpg'\n",
    "\n",
    "############################################################################\n",
    "# YOU DO NOT NEED TO CHANGE ANYTHING BELOW THIS LINE TO RUN THIS EXAMPLE\n",
    "############################################################################\n",
    "\n",
    "\n",
    "\n",
    "channel = ClarifaiChannel.get_grpc_channel()\n",
    "stub = service_pb2_grpc.V2Stub(channel)\n",
    "\n",
    "metadata = (('authorization', 'Key ' + PAT),)\n",
    "\n",
    "userDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n",
    "\n",
    "post_model_outputs_response = stub.PostModelOutputs(\n",
    "    service_pb2.PostModelOutputsRequest(\n",
    "        user_app_id=userDataObject,  # The userDataObject is created in the overview and is required when using a PAT\n",
    "        model_id=MODEL_ID,\n",
    "        version_id=MODEL_VERSION_ID,  # This is optional. Defaults to the latest model version\n",
    "        inputs=[\n",
    "            resources_pb2.Input(\n",
    "                data=resources_pb2.Data(\n",
    "                    image=resources_pb2.Image(\n",
    "                        url=IMAGE_URL\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    metadata=metadata\n",
    ")\n",
    "if post_model_outputs_response.status.code != status_code_pb2.SUCCESS:\n",
    "    print(post_model_outputs_response.status)\n",
    "    raise Exception(\"Post model outputs failed, status: \" + post_model_outputs_response.status.description)\n",
    "\n",
    "# Since we have one input, one output will exist here\n",
    "output = post_model_outputs_response.outputs[0]\n",
    "\n",
    "print(\"Predicted concepts:\")\n",
    "for concept in output.data.concepts:\n",
    "    print(\"%s %.2f\" % (concept.name, concept.value))\n",
    "\n",
    "# Uncomment this line to print the full Response JSON\n",
    "#print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cv2清洗数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_photo = 'D:\\paper\\二手产品\\headpicture' # 所有photo所在的文件夹目录\n",
    "#\n",
    "files_list = os.listdir(path_photo) # 得到文件夹下的所有文件名称，存在字符串列表中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成image_resnet50_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102967424/102967424 [==============================] - 19s 0us/step\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10808/310933754.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mres_dt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sku_key\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_l\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mres_dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres_dt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sku_key\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"featureResNet50_{i}\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mres_dt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/paper/二手产品/dlresnet50_features.parquet\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_parquet\u001b[1;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   2887\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2889\u001b[1;33m         return to_parquet(\n\u001b[0m\u001b[0;32m   2890\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2891\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[0mpartition_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m     \u001b[0mimpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFilePath\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mWriteBuffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[0merror_msgs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"\\n - \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         raise ImportError(\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[1;34m\"Unable to find a usable engine; \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;34m\"tried using: 'pyarrow', 'fastparquet'.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "resnet = ResNet50()\n",
    "intermediate_model = Model(inputs=resnet.input,\n",
    "                           outputs=resnet.layers[-2].output)\n",
    "\n",
    "image_folder = \"D:\\paper\\二手产品\\headpicture\"\n",
    "file_l = [i for i in os.listdir(image_folder) if i[-4:]==\".png\"]\n",
    "img_l = []\n",
    "for file in file_l:\n",
    "    img = image.load_img(f\"{image_folder}/{file}\", target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img_l.append(img)\n",
    "img_l = [preprocess_input(x) for x in img_l]\n",
    "x_arr = np.stack(img_l)\n",
    "preds_arr = intermediate_model.predict(x_arr, verbose=0)\n",
    "res_dt = pd.DataFrame(preds_arr, columns = [f\"featureResNet50_{i}\" for i in range(preds_arr.shape[1])])\n",
    "res_dt[\"sku_key\"] = [i[:-4] for i in file_l]\n",
    "res_dt = res_dt[[\"sku_key\"]+[f\"featureResNet50_{i}\" for i in range(preds_arr.shape[1])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku_key</th>\n",
       "      <th>featureResNet50_0</th>\n",
       "      <th>featureResNet50_1</th>\n",
       "      <th>featureResNet50_2</th>\n",
       "      <th>featureResNet50_3</th>\n",
       "      <th>featureResNet50_4</th>\n",
       "      <th>featureResNet50_5</th>\n",
       "      <th>featureResNet50_6</th>\n",
       "      <th>featureResNet50_7</th>\n",
       "      <th>featureResNet50_8</th>\n",
       "      <th>...</th>\n",
       "      <th>featureResNet50_2038</th>\n",
       "      <th>featureResNet50_2039</th>\n",
       "      <th>featureResNet50_2040</th>\n",
       "      <th>featureResNet50_2041</th>\n",
       "      <th>featureResNet50_2042</th>\n",
       "      <th>featureResNet50_2043</th>\n",
       "      <th>featureResNet50_2044</th>\n",
       "      <th>featureResNet50_2045</th>\n",
       "      <th>featureResNet50_2046</th>\n",
       "      <th>featureResNet50_2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>head_1012174178542862346</td>\n",
       "      <td>0.420022</td>\n",
       "      <td>0.870905</td>\n",
       "      <td>0.016568</td>\n",
       "      <td>0.566109</td>\n",
       "      <td>0.176106</td>\n",
       "      <td>0.046738</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.330081</td>\n",
       "      <td>0.114168</td>\n",
       "      <td>...</td>\n",
       "      <td>1.094419</td>\n",
       "      <td>0.313886</td>\n",
       "      <td>0.018884</td>\n",
       "      <td>0.100397</td>\n",
       "      <td>0.104682</td>\n",
       "      <td>0.321746</td>\n",
       "      <td>0.090264</td>\n",
       "      <td>0.023384</td>\n",
       "      <td>0.495674</td>\n",
       "      <td>0.097876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>head_1069754080775389200</td>\n",
       "      <td>0.325530</td>\n",
       "      <td>3.163739</td>\n",
       "      <td>0.263346</td>\n",
       "      <td>1.067068</td>\n",
       "      <td>1.144615</td>\n",
       "      <td>0.089846</td>\n",
       "      <td>0.742594</td>\n",
       "      <td>1.755014</td>\n",
       "      <td>0.684139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.151794</td>\n",
       "      <td>1.135919</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.114006</td>\n",
       "      <td>0.083381</td>\n",
       "      <td>0.194050</td>\n",
       "      <td>0.442614</td>\n",
       "      <td>3.513230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>head_1097742638033567747</td>\n",
       "      <td>1.363054</td>\n",
       "      <td>3.000543</td>\n",
       "      <td>0.950407</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>0.958617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369782</td>\n",
       "      <td>4.404724</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>...</td>\n",
       "      <td>1.722150</td>\n",
       "      <td>0.814232</td>\n",
       "      <td>0.014491</td>\n",
       "      <td>0.081966</td>\n",
       "      <td>0.392121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046088</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.902650</td>\n",
       "      <td>3.874696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>head_1309132874270959312</td>\n",
       "      <td>0.720076</td>\n",
       "      <td>0.708608</td>\n",
       "      <td>0.203013</td>\n",
       "      <td>0.022486</td>\n",
       "      <td>3.536333</td>\n",
       "      <td>0.233563</td>\n",
       "      <td>0.203528</td>\n",
       "      <td>0.324958</td>\n",
       "      <td>5.168813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.191354</td>\n",
       "      <td>1.059663</td>\n",
       "      <td>0.474383</td>\n",
       "      <td>0.107552</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.090938</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.331910</td>\n",
       "      <td>0.138341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>head_1382365966036960256</td>\n",
       "      <td>0.153551</td>\n",
       "      <td>2.270304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322040</td>\n",
       "      <td>0.375105</td>\n",
       "      <td>0.092387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048603</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006289</td>\n",
       "      <td>0.091365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117812</td>\n",
       "      <td>0.867149</td>\n",
       "      <td>0.046039</td>\n",
       "      <td>0.265339</td>\n",
       "      <td>1.471083</td>\n",
       "      <td>0.274653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6543</th>\n",
       "      <td>head_1719686334212133376</td>\n",
       "      <td>0.038806</td>\n",
       "      <td>4.911072</td>\n",
       "      <td>1.221609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227566</td>\n",
       "      <td>0.062860</td>\n",
       "      <td>0.190482</td>\n",
       "      <td>0.306964</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157251</td>\n",
       "      <td>0.554050</td>\n",
       "      <td>0.194177</td>\n",
       "      <td>0.226269</td>\n",
       "      <td>0.080892</td>\n",
       "      <td>0.682579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>head_1719686700364911104</td>\n",
       "      <td>0.885669</td>\n",
       "      <td>0.988088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166708</td>\n",
       "      <td>2.132010</td>\n",
       "      <td>0.131538</td>\n",
       "      <td>0.355934</td>\n",
       "      <td>2.221939</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040420</td>\n",
       "      <td>0.031588</td>\n",
       "      <td>0.408028</td>\n",
       "      <td>1.931747</td>\n",
       "      <td>0.516376</td>\n",
       "      <td>0.493323</td>\n",
       "      <td>0.183661</td>\n",
       "      <td>0.062651</td>\n",
       "      <td>0.176293</td>\n",
       "      <td>2.953348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6545</th>\n",
       "      <td>head_1719687442434183680</td>\n",
       "      <td>0.367826</td>\n",
       "      <td>0.804443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.239426</td>\n",
       "      <td>0.253165</td>\n",
       "      <td>0.438962</td>\n",
       "      <td>0.757302</td>\n",
       "      <td>1.534401</td>\n",
       "      <td>0.047888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110566</td>\n",
       "      <td>0.223090</td>\n",
       "      <td>0.018783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050830</td>\n",
       "      <td>1.477176</td>\n",
       "      <td>0.042210</td>\n",
       "      <td>1.302407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6546</th>\n",
       "      <td>head_811358685860659202</td>\n",
       "      <td>0.799816</td>\n",
       "      <td>2.649730</td>\n",
       "      <td>0.249945</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.052568</td>\n",
       "      <td>0.270316</td>\n",
       "      <td>0.372865</td>\n",
       "      <td>0.694616</td>\n",
       "      <td>0.130266</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066735</td>\n",
       "      <td>0.042143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.994129</td>\n",
       "      <td>0.088379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142908</td>\n",
       "      <td>1.171257</td>\n",
       "      <td>1.139945</td>\n",
       "      <td>3.025183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6547</th>\n",
       "      <td>head_860434193035919366</td>\n",
       "      <td>0.255899</td>\n",
       "      <td>3.264378</td>\n",
       "      <td>0.173982</td>\n",
       "      <td>0.219032</td>\n",
       "      <td>0.274717</td>\n",
       "      <td>0.019021</td>\n",
       "      <td>0.163253</td>\n",
       "      <td>0.036682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199865</td>\n",
       "      <td>0.044438</td>\n",
       "      <td>0.126593</td>\n",
       "      <td>0.086253</td>\n",
       "      <td>0.088006</td>\n",
       "      <td>0.081437</td>\n",
       "      <td>1.353312</td>\n",
       "      <td>0.457972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.292322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6548 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       sku_key  featureResNet50_0  featureResNet50_1  \\\n",
       "0     head_1012174178542862346           0.420022           0.870905   \n",
       "1     head_1069754080775389200           0.325530           3.163739   \n",
       "2     head_1097742638033567747           1.363054           3.000543   \n",
       "3     head_1309132874270959312           0.720076           0.708608   \n",
       "4     head_1382365966036960256           0.153551           2.270304   \n",
       "...                        ...                ...                ...   \n",
       "6543  head_1719686334212133376           0.038806           4.911072   \n",
       "6544  head_1719686700364911104           0.885669           0.988088   \n",
       "6545  head_1719687442434183680           0.367826           0.804443   \n",
       "6546   head_811358685860659202           0.799816           2.649730   \n",
       "6547   head_860434193035919366           0.255899           3.264378   \n",
       "\n",
       "      featureResNet50_2  featureResNet50_3  featureResNet50_4  \\\n",
       "0              0.016568           0.566109           0.176106   \n",
       "1              0.263346           1.067068           1.144615   \n",
       "2              0.950407           0.070472           0.958617   \n",
       "3              0.203013           0.022486           3.536333   \n",
       "4              0.000000           0.000000           0.322040   \n",
       "...                 ...                ...                ...   \n",
       "6543           1.221609           0.000000           0.227566   \n",
       "6544           0.000000           0.166708           2.132010   \n",
       "6545           0.000000           2.239426           0.253165   \n",
       "6546           0.249945           0.000656           0.052568   \n",
       "6547           0.173982           0.219032           0.274717   \n",
       "\n",
       "      featureResNet50_5  featureResNet50_6  featureResNet50_7  \\\n",
       "0              0.046738           0.000269           0.330081   \n",
       "1              0.089846           0.742594           1.755014   \n",
       "2              0.000000           0.369782           4.404724   \n",
       "3              0.233563           0.203528           0.324958   \n",
       "4              0.375105           0.092387           0.000000   \n",
       "...                 ...                ...                ...   \n",
       "6543           0.062860           0.190482           0.306964   \n",
       "6544           0.131538           0.355934           2.221939   \n",
       "6545           0.438962           0.757302           1.534401   \n",
       "6546           0.270316           0.372865           0.694616   \n",
       "6547           0.019021           0.163253           0.036682   \n",
       "\n",
       "      featureResNet50_8  ...  featureResNet50_2038  featureResNet50_2039  \\\n",
       "0              0.114168  ...              1.094419              0.313886   \n",
       "1              0.684139  ...              0.000000              0.721698   \n",
       "2              0.001635  ...              1.722150              0.814232   \n",
       "3              5.168813  ...              0.005681              0.191354   \n",
       "4              0.048603  ...              1.006289              0.091365   \n",
       "...                 ...  ...                   ...                   ...   \n",
       "6543           0.003261  ...              0.091791              0.000000   \n",
       "6544           0.037771  ...              0.040420              0.031588   \n",
       "6545           0.047888  ...              0.110566              0.223090   \n",
       "6546           0.130266  ...              1.066735              0.042143   \n",
       "6547           0.000000  ...              0.199865              0.044438   \n",
       "\n",
       "      featureResNet50_2040  featureResNet50_2041  featureResNet50_2042  \\\n",
       "0                 0.018884              0.100397              0.104682   \n",
       "1                 0.151794              1.135919              0.006155   \n",
       "2                 0.014491              0.081966              0.392121   \n",
       "3                 1.059663              0.474383              0.107552   \n",
       "4                 0.000000              0.000000              0.117812   \n",
       "...                    ...                   ...                   ...   \n",
       "6543              0.011773              0.000000              0.157251   \n",
       "6544              0.408028              1.931747              0.516376   \n",
       "6545              0.018783              0.000000              0.268281   \n",
       "6546              0.000000              0.994129              0.088379   \n",
       "6547              0.126593              0.086253              0.088006   \n",
       "\n",
       "      featureResNet50_2043  featureResNet50_2044  featureResNet50_2045  \\\n",
       "0                 0.321746              0.090264              0.023384   \n",
       "1                 0.114006              0.083381              0.194050   \n",
       "2                 0.000000              0.046088              0.030700   \n",
       "3                 0.839216              0.090938              0.002466   \n",
       "4                 0.867149              0.046039              0.265339   \n",
       "...                    ...                   ...                   ...   \n",
       "6543              0.554050              0.194177              0.226269   \n",
       "6544              0.493323              0.183661              0.062651   \n",
       "6545              0.000000              0.050830              1.477176   \n",
       "6546              0.000000              0.142908              1.171257   \n",
       "6547              0.081437              1.353312              0.457972   \n",
       "\n",
       "      featureResNet50_2046  featureResNet50_2047  \n",
       "0                 0.495674              0.097876  \n",
       "1                 0.442614              3.513230  \n",
       "2                 0.902650              3.874696  \n",
       "3                 0.331910              0.138341  \n",
       "4                 1.471083              0.274653  \n",
       "...                    ...                   ...  \n",
       "6543              0.080892              0.682579  \n",
       "6544              0.176293              2.953348  \n",
       "6545              0.042210              1.302407  \n",
       "6546              1.139945              3.025183  \n",
       "6547              0.000000              3.292322  \n",
       "\n",
       "[6548 rows x 2049 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dt.to_parquet(\"D:/paper/二手产品/dlresnet50_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_image_mask_and_random_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### produces RGB color-clusters over using KMeans method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.046920061111450195,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 6548,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5669c008a74612ac0f33376d00b9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.07 GiB for an array with shape (411757518,) and data type uint64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1328/2735668976.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mcolor_dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pixel_vals\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"g\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"weight\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mcolor_dt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sku_key\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sku_key\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pixel_vals\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[0mcolor_dt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"segment\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_dt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"g\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"b\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3948\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3949\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3950\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3952\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4141\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4142\u001b[0m         \"\"\"\n\u001b[1;32m-> 4143\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4145\u001b[0m         if (\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4869\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4870\u001b[0m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4871\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4873\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_convert_platform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mmaybe_convert_platform\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_dtype_obj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_convert_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.07 GiB for an array with shape (411757518,) and data type uint64"
     ]
    }
   ],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "###### PARAMETERS ######\n",
    "num_clusters = 30 # number of color clusters to use\n",
    "########################\n",
    "\n",
    "\n",
    "\n",
    "base_pic_folder = \"D:/paper/secondhand/headpicture\"#opencv 不能出现中文名\n",
    "file_l = [i for i in os.listdir(base_pic_folder) if i[-4:]==\".png\"]\n",
    "arr_d = {}\n",
    "arr_d[\"pixel_vals\"] = []\n",
    "arr_d[\"sku_key\"] = {\"pixel_vals\":[]}\n",
    "for file in tqdm(file_l):\n",
    "    img = cv2.imread(f\"{base_pic_folder}/{file}\")\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    non_back_arr = (gray_img<=250)    \n",
    "    img_arr = img_rgb[non_back_arr]\n",
    "    dt = pd.DataFrame(img_arr,columns=[\"r\",\"g\",\"b\"])\n",
    "    dt[\"weight\"] = 1\n",
    "    temp_dt = dt.groupby([\"r\",\"g\",\"b\"], as_index=False).sum()\n",
    "    arr_d[\"pixel_vals\"].append(temp_dt.values)\n",
    "    arr_d[\"sku_key\"][\"pixel_vals\"].extend([file[:-4]]*temp_dt.shape[0])        \n",
    "\n",
    "for d in arr_d:    \n",
    "    if d!=\"sku_key\":\n",
    "        arr_d[d] = np.vstack(arr_d[d])\n",
    "\n",
    "\n",
    "os.makedirs(\"./RESULTS/models/\", exist_ok = True)\n",
    "temp_dt = pd.DataFrame(arr_d[\"pixel_vals\"],columns=[\"r\",\"g\",\"b\",\"weight\"])\n",
    "temp_dt = temp_dt.groupby([\"r\",\"g\",\"b\"], as_index=False).sum()\n",
    "mod = MiniBatchKMeans(num_clusters, batch_size=1000000, verbose=0, random_state=0)\n",
    "\n",
    "mod.fit(temp_dt[[\"r\",\"g\",\"b\"]].values,sample_weight=temp_dt[\"weight\"].values)\n",
    "c_centers_arr = mod.cluster_centers_\n",
    "np.save(\"./RESULTS/models/color_clusters\",mod)\n",
    "\n",
    "color_dt = pd.DataFrame(arr_d[\"pixel_vals\"],columns=[\"r\",\"g\",\"b\",\"weight\"])\n",
    "color_dt[\"sku_key\"] = arr_d[\"sku_key\"][\"pixel_vals\"]\n",
    "color_dt[\"segment\"] = mod.predict(color_dt[[\"r\",\"g\",\"b\"]])\n",
    "\n",
    "color_dt = color_dt.groupby([\"sku_key\",\"segment\"], as_index=False)[\"weight\"].sum()\n",
    "temp_dt = color_dt.groupby([\"sku_key\"],as_index=False)[\"weight\"].sum()\n",
    "color_dt = color_dt.merge(temp_dt,on=\"sku_key\",how=\"left\")\n",
    "color_dt[\"share\"] = color_dt[\"weight_x\"]/color_dt[\"weight_y\"]\n",
    "del color_dt[\"weight_x\"]\n",
    "del color_dt[\"weight_y\"]\n",
    "fin_dt = color_dt[[\"sku_key\"]].drop_duplicates()\n",
    "for i in range(c_centers_arr.shape[0]):\n",
    "    temp_dt = color_dt[color_dt[\"segment\"]==i]\n",
    "    del temp_dt[\"segment\"]\n",
    "    fin_dt = fin_dt.merge(temp_dt,on=\"sku_key\",how=\"left\").fillna(0).rename(columns={\"share\":\"cluster_share_rgb_\"+str(i)})\n",
    "fin_dt.to_parquet(\"./_data/color_clusters_rgb.parquet\")\n",
    "\n",
    "h = 5\n",
    "w = int(c_centers_arr.shape[0]/h)\n",
    "f, axarr = plt.subplots(h,w,figsize=(7,7)) \n",
    "\n",
    "for i in range(c_centers_arr.shape[0]):\n",
    "    im = (np.ones((10,10,3))*c_centers_arr[i]).astype(np.uint8)\n",
    "    axarr[i%h][i//h].imshow(im)\n",
    "    axarr[i%h][i//h].set_title(\"Cluster \"+str(i))\n",
    "    axarr[i%h][i//h].axis('off')\n",
    "f.tight_layout(pad= 0.4)\n",
    "os.makedirs(\"./RESULTS/final_figures/\", exist_ok = True)\n",
    "f.savefig(\"./RESULTS/final_figures/Cluster_centers_rgb.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PARAMETERS ######\n",
    "num_clusters = 30 # number of color clusters to use\n",
    "########################\n",
    "\n",
    "\n",
    "\n",
    "base_pic_folder = \"D:/paper/secondhand/headpicture\"#opencv 不能出现中文名\n",
    "file_l = [i for i in os.listdir(base_pic_folder) if i[-4:]==\".png\"]\n",
    "arr_d = {}\n",
    "arr_d[\"pixel_vals\"] = []\n",
    "arr_d[\"sku_key\"] = {\"pixel_vals\":[]}\n",
    "for file in tqdm(file_l):\n",
    "    img = cv2.imread(f\"{base_pic_folder}/{file}\")\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    non_back_arr = (gray_img<=250)    \n",
    "    img_arr = img_rgb[non_back_arr]\n",
    "    dt = pd.DataFrame(img_arr,columns=[\"r\",\"g\",\"b\"])\n",
    "    dt[\"weight\"] = 1\n",
    "    temp_dt = dt.groupby([\"r\",\"g\",\"b\"], as_index=False).sum()\n",
    "    arr_d[\"pixel_vals\"].append(temp_dt.values)\n",
    "    arr_d[\"sku_key\"][\"pixel_vals\"].extend([file[:-4]]*temp_dt.shape[0])        \n",
    "\n",
    "for d in arr_d:    \n",
    "    if d!=\"sku_key\":\n",
    "        arr_d[d] = np.vstack(arr_d[d])\n",
    "\n",
    "\n",
    "os.makedirs(\"./RESULTS/models/\", exist_ok = True)\n",
    "temp_dt = pd.DataFrame(arr_d[\"pixel_vals\"],columns=[\"r\",\"g\",\"b\",\"weight\"])\n",
    "temp_dt = temp_dt.groupby([\"r\",\"g\",\"b\"], as_index=False).sum()\n",
    "mod = MiniBatchKMeans(num_clusters, batch_size=1000000, verbose=0, random_state=0)\n",
    "\n",
    "mod.fit(temp_dt[[\"r\",\"g\",\"b\"]].values,sample_weight=temp_dt[\"weight\"].values)\n",
    "c_centers_arr = mod.cluster_centers_\n",
    "np.save(\"./RESULTS/models/color_clusters\",mod)\n",
    "\n",
    "color_dt = pd.DataFrame(arr_d[\"pixel_vals\"],columns=[\"r\",\"g\",\"b\",\"weight\"])\n",
    "color_dt[\"sku_key\"] = arr_d[\"sku_key\"][\"pixel_vals\"]\n",
    "color_dt[\"segment\"] = mod.predict(color_dt[[\"r\",\"g\",\"b\"]])\n",
    "\n",
    "color_dt = color_dt.groupby([\"sku_key\",\"segment\"], as_index=False)[\"weight\"].sum()\n",
    "temp_dt = color_dt.groupby([\"sku_key\"],as_index=False)[\"weight\"].sum()\n",
    "color_dt = color_dt.merge(temp_dt,on=\"sku_key\",how=\"left\")\n",
    "color_dt[\"share\"] = color_dt[\"weight_x\"]/color_dt[\"weight_y\"]\n",
    "del color_dt[\"weight_x\"]\n",
    "del color_dt[\"weight_y\"]\n",
    "fin_dt = color_dt[[\"sku_key\"]].drop_duplicates()\n",
    "for i in range(c_centers_arr.shape[0]):\n",
    "    temp_dt = color_dt[color_dt[\"segment\"]==i]\n",
    "    del temp_dt[\"segment\"]\n",
    "    fin_dt = fin_dt.merge(temp_dt,on=\"sku_key\",how=\"left\").fillna(0).rename(columns={\"share\":\"cluster_share_rgb_\"+str(i)})\n",
    "fin_dt.to_parquet(\"./_data/color_clusters_rgb.parquet\")\n",
    "\n",
    "h = 5\n",
    "w = int(c_centers_arr.shape[0]/h)\n",
    "f, axarr = plt.subplots(h,w,figsize=(7,7)) \n",
    "\n",
    "for i in range(c_centers_arr.shape[0]):\n",
    "    im = (np.ones((10,10,3))*c_centers_arr[i]).astype(np.uint8)\n",
    "    axarr[i%h][i//h].imshow(im)\n",
    "    axarr[i%h][i//h].set_title(\"Cluster \"+str(i))\n",
    "    axarr[i%h][i//h].axis('off')\n",
    "f.tight_layout(pad= 0.4)\n",
    "os.makedirs(\"./RESULTS/final_figures/\", exist_ok = True)\n",
    "f.savefig(\"./RESULTS/final_figures/Cluster_centers_rgb.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "识别结果已保存到 upperbody_detection_results2.csv 文件.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 加载上半身检测器\n",
    "upperbody_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_upperbody.xml')\n",
    "\n",
    "# 文件夹路径\n",
    "folder_path = r'D:\\paper\\secondhand\\headpicture'\n",
    "\n",
    "# 创建一个 DataFrame 用于存储结果\n",
    "result_df = pd.DataFrame(columns=['Image', 'HasUpperBody'])\n",
    "\n",
    "# 遍历文件夹中的所有图像文件\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "        # 构建图像文件的完整路径\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # 读取图像\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        if img is not None:\n",
    "            # 转换为灰度图像\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # 使用上半身检测器检测上半身\n",
    "            upper_bodies = upperbody_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "            # 判断是否检测到上半身\n",
    "            has_upper_body = len(upper_bodies) > 0\n",
    "\n",
    "            # 将结果添加到 DataFrame\n",
    "            result_df = result_df._append({'Image': filename, 'HasUpperBody': has_upper_body}, ignore_index=True)\n",
    "\n",
    "# 将结果保存到 CSV 文件\n",
    "result_df.to_csv('upperbody_detection_results2.csv', index=False)\n",
    "\n",
    "print(\"识别结果已保存到 upperbody_detection_results2.csv 文件.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检测结果已保存到 detection_results.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "# 设置 YOLO 相关文件的路径\n",
    "yolo_config_path = \"C:/Users/lenovo/darknet/cfg/yolov4.cfg\"\n",
    "yolo_weights_path = \"C:/Users/lenovo/darknet/cfg/yolov4.weights\"\n",
    "yolo_names_path = \"C:/Users/lenovo/darknet/data/coco.names\"\n",
    "\n",
    "# 读取 YOLO 模型\n",
    "net = cv2.dnn.readNet(yolo_weights_path, yolo_config_path)\n",
    "\n",
    "# 加载 COCO 数据集类别名称\n",
    "with open(yolo_names_path, 'r') as f:\n",
    "    classes = f.read().strip().split('\\n')\n",
    "\n",
    "# 图像文件夹路径\n",
    "image_folder = r\"D:\\paper\\secondhand\\headpicture\"\n",
    "\n",
    "# 结果保存的 CSV 文件\n",
    "output_csv_path = \"detection_results.csv\"\n",
    "\n",
    "# 创建 CSV 文件并写入列名\n",
    "with open(output_csv_path, mode='w', newline='') as csvfile:\n",
    "    fieldnames = ['Image_Name', 'Person_Detected']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "\n",
    "    # 加载图像\n",
    "    image_names = [file for file in os.listdir(image_folder) if file.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    for image_name in image_names:\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        # 构建 YOLO 输入 blob\n",
    "        blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # 获取 YOLO 输出层信息\n",
    "        output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "        layer_outputs = net.forward(output_layers_names)\n",
    "\n",
    "        # 处理 YOLO 输出\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        for output in layer_outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "\n",
    "                if confidence > 0.5 and class_id == 0:  # 类别编号 0 代表人\n",
    "                    center_x, center_y, w, h = (detection[0:4] * np.array([width, height, width, height])).astype(int)\n",
    "                    x, y = int(center_x - w / 2), int(center_y - h / 2)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        # 非极大值抑制\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "        # 写入 CSV 文件\n",
    "        if len(indices) > 0:\n",
    "            writer.writerow({'Image_Name': image_name, 'Person_Detected': 'Yes'})\n",
    "        else:\n",
    "            writer.writerow({'Image_Name': image_name, 'Person_Detected': 'No'})\n",
    "\n",
    "print(f\"检测结果已保存到 {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 加载DataFrame\n",
    "excel_path = \"C:\\\\Users\\\\lenovo\\\\Documents\\\\WPSDrive\\\\1524623893\\\\WPS企业云盘\\\\中南财经政法大学\\\\我的企业文档\\\\二手产品\\\\进度\\\\result_clean.xlsx\"\n",
    "data = pd.read_excel(excel_path)\n",
    "df = data.head(100)\n",
    "# 图像文件夹路径\n",
    "image_dir = \"D:\\\\paper\\\\secondhand\\\\headpicture\"\n",
    "\n",
    "# 使用ImageDataGenerator进行数据增强\n",
    "datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# 使用ImageDataGenerator从DataFrame中读取图像\n",
    "generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=image_dir,\n",
    "    x_col=\"Image\",  # 图像名称列\n",
    "    y_col=\" authentic\",  # 标签列\n",
    "    target_size=(225, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='raw',  # 回归任务使用 'raw'\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 58s 17s/step - loss: 90.0390 - mean_absolute_error: 8.2035\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 58s 13s/step - loss: 22.9777 - mean_absolute_error: 4.0645\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 56s 12s/step - loss: 16.2867 - mean_absolute_error: 3.3579\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 55s 12s/step - loss: 7.5548 - mean_absolute_error: 2.1245\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 54s 12s/step - loss: 6.2239 - mean_absolute_error: 2.0036\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 51s 11s/step - loss: 4.3465 - mean_absolute_error: 1.5534\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 49s 16s/step - loss: 3.4507 - mean_absolute_error: 1.4557\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 51s 11s/step - loss: 2.9999 - mean_absolute_error: 1.3815\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 49s 15s/step - loss: 2.4482 - mean_absolute_error: 1.2306\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 49s 11s/step - loss: 1.8849 - mean_absolute_error: 1.1206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24331d3eeb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载VGG16模型，不包括顶层（全连接层）\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(225, 300, 3))\n",
    "\n",
    "# 获取VGG16模型的输出\n",
    "vgg_output = base_model.output\n",
    "\n",
    "# 添加自定义全连接层\n",
    "flatten_layer = Flatten()(vgg_output)\n",
    "dense_layer1 = Dense(256, activation='relu')(flatten_layer)\n",
    "dropout_layer = Dropout(0.5)(dense_layer1)\n",
    "output_layer = Dense(1, activation='linear')(dropout_layer)\n",
    "\n",
    "# 构建自定义模型\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "# 冻结 VGG16 的卷积层\n",
    "base_model.trainable = False\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(), metrics=['mean_absolute_error'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 27s 6s/step\n",
      "                           Image   authentic  predicted_authentic\n",
      "0   head_1012174178542862346.png         5.0             4.141305\n",
      "1   head_1069754080775389200.png         4.0             3.650904\n",
      "2   head_1097742638033567747.png         4.0             4.496332\n",
      "3   head_1414034614477571072.png         4.0             3.629560\n",
      "4   head_1414035389098410496.png         4.0             3.564136\n",
      "..                           ...         ...                  ...\n",
      "95  head_1716698469307093504.png         4.0             4.391719\n",
      "96  head_1716700310795292672.png         4.0             3.405168\n",
      "97  head_1716701680162280448.png         3.0             1.918617\n",
      "98  head_1716714810643878912.png         4.0             3.933315\n",
      "99  head_1716721666390642688.png         4.0             3.282511\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp/ipykernel_12652/2237088283.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['predicted_authentic'] = predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6424 validated image filenames.\n",
      "201/201 [==============================] - 1631s 8s/step\n",
      "                             Image  predicted_authentic\n",
      "0     head_1012174178542862346.png             4.501143\n",
      "1     head_1069754080775389200.png             3.424792\n",
      "2     head_1097742638033567747.png             3.508769\n",
      "3     head_1414034614477571072.png             3.512487\n",
      "4     head_1414035389098410496.png             3.490082\n",
      "...                            ...                  ...\n",
      "6419  head_1719686334212133376.png             3.270895\n",
      "6420  head_1719686700364911104.png             3.283749\n",
      "6421  head_1719687442434183680.png             3.239830\n",
      "6422   head_811358685860659202.png             3.910758\n",
      "6423   head_860434193035919366.png             3.561357\n",
      "\n",
      "[6424 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 使用训练好的模型进行预测\n",
    "predictions = model.predict(generator)\n",
    "\n",
    "# 将预测结果添加到DataFrame中\n",
    "df['predicted_authentic'] = predictions\n",
    "\n",
    "# 打印预测结果\n",
    "print(df[['Image', ' authentic', 'predicted_authentic']])\n",
    "\n",
    "# 为其他数据打标签\n",
    "# 假设有一个新的DataFrame称为 new_data，包含待打标签的图像名称列为 \"Image\"\n",
    "new_data =  data\n",
    "\n",
    "# 使用ImageDataGenerator进行数据增强并从新的DataFrame中读取图像\n",
    "new_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=new_data,\n",
    "    directory=image_dir,\n",
    "    x_col=\"Image\",\n",
    "    target_size=(225, 300),\n",
    "    batch_size=32,\n",
    "    class_mode=None,  # 设置为 None，因为这里我们不需要标签\n",
    "    shuffle=False  # 保持顺序\n",
    ")\n",
    "\n",
    "# 使用模型进行预测\n",
    "new_predictions = model.predict(new_generator)\n",
    "\n",
    "# 将预测结果添加到新的DataFrame中\n",
    "new_data['predicted_authentic'] = new_predictions.flatten()\n",
    "\n",
    "# 打印为其他数据打标签的结果\n",
    "print(new_data[['Image', 'predicted_authentic']])\n",
    "\n",
    "new_data.to_excel('D:\\paper\\secondhand\\iv\\VGG162.xlsx')\n",
    "df.to_excel('D:\\paper\\secondhand\\iv\\predictions2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: [ 4.68596989  4.43685466  1.60139617  1.61597329 -6.80565466]\n",
      "P-Value: [2.84381456e-06 9.28069239e-06 1.09338384e-01 1.06149209e-01\n",
      " 1.09698203e-11]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12652/2942327190.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# 判断差异是否显著\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mp_value\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"差异显著\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"D:\\paper\\secondhand\\iv\\VGG16.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 分组字段\n",
    "grouped_field = \"Person_Detected\"\n",
    "\n",
    "# 需要比较的数据字段\n",
    "columns_to_compare = [\"predicted_polluted\", \"predicted_authentic\", \"想要量\", \"浏览量\", \"总评分\"]\n",
    "\n",
    "# 拆分数据为两组\n",
    "grouped_data = df.groupby(grouped_field)\n",
    "group1 = grouped_data.get_group(\"Yes\")[columns_to_compare]\n",
    "group2 = grouped_data.get_group(\"No\")[columns_to_compare]\n",
    "\n",
    "# 执行t检验\n",
    "t_statistic, p_value = ttest_ind(group1, group2)\n",
    "\n",
    "# 显示结果\n",
    "print(f\"T-Statistic: {t_statistic}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "# 判断差异是否显著\n",
    "if p_value < 0.05:\n",
    "    print(\"差异显著\")\n",
    "else:\n",
    "    print(\"差异不显著\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12652/3765658929.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# 创建浏览量的分布图\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'浏览量'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'skyblue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'浏览量分布图'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36mhistplot\u001b[1;34m(data, x, y, hue, weights, stat, bins, binwidth, binrange, discrete, cumulative, common_bins, common_norm, multiple, element, fill, shrink, kde, kde_kws, line_kws, thresh, pthresh, pmax, cbar, cbar_ax, cbar_kws, palette, hue_order, hue_norm, color, log_scale, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m   1414\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munivariate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1416\u001b[1;33m         p.plot_univariate_histogram(\n\u001b[0m\u001b[0;32m   1417\u001b[0m             \u001b[0mmultiple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1418\u001b[0m             \u001b[0melement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36mplot_univariate_histogram\u001b[1;34m(self, multiple, element, fill, common_norm, common_bins, shrink, kde, kde_kws, color, legend, line_kws, estimate_kws, **plot_kws)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m                 \u001b[0mline_kws\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"color\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_color\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m                 line, = ax.plot(\n\u001b[0m\u001b[0;32m    652\u001b[0m                     \u001b[1;33m*\u001b[0m\u001b[0mline_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mline_kws\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m                 )\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1630\u001b[0m         \"\"\"\n\u001b[0;32m   1631\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1632\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1633\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                     message='Support for multi-dimensional indexing')\n\u001b[0;32m   1326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m                 \u001b[1;31m# we have definitely hit a pandas index or series object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;31m# cast to a numpy array.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5197\u001b[0m         \u001b[1;31m# Because we ruled out integer above, we always get an arraylike here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5198\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5199\u001b[1;33m             \u001b[0mdisallow_ndim_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5201\u001b[0m         \u001b[1;31m# NB: Using _constructor._simple_new would break if MultiIndex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lenovo\\.virtualenvs\\pythonProject\\lib\\site-packages\\pandas\\core\\indexers\\utils.py\u001b[0m in \u001b[0;36mdisallow_ndim_indexing\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \"\"\"\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    344\u001b[0m             \u001b[1;34m\"Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m             \u001b[1;34m\"supported. Convert to a numpy array before indexing instead.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 df 是包含浏览量和想要量的 DataFrame，列名分别为 '浏览量' 和 '想要量'\n",
    "# Replace '浏览量' and '想要量' with your actual column names\n",
    "\n",
    "# 设置图形大小\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 创建浏览量的分布图\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.histplot(df['浏览量'].values, bins=30, kde=True, color='skyblue')\n",
    "plt.title('浏览量分布图')\n",
    "\n",
    "# 创建想要量的分布图\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.histplot(df['想要量'].values, bins=30, kde=True, color='salmon')\n",
    "plt.title('想要量分布图')\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent Variable: 想要量\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    想要量   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.6821\n",
      "Date:                Sat, 20 Jan 2024   Prob (F-statistic):              0.506\n",
      "Time:                        13:01:28   Log-Likelihood:                -14618.\n",
      "No. Observations:                6424   AIC:                         2.924e+04\n",
      "Df Residuals:                    6421   BIC:                         2.926e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.4545      0.378      1.201      0.230      -0.287       1.196\n",
      "predicted_polluted     -0.0795      0.072     -1.112      0.266      -0.220       0.061\n",
      "predicted_authentic    -0.0165      0.083     -0.200      0.842      -0.179       0.146\n",
      "==============================================================================\n",
      "Omnibus:                    23608.968   Durbin-Watson:                   1.900\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):      10189604134.831\n",
      "Skew:                          77.825   Prob(JB):                         0.00\n",
      "Kurtosis:                    6170.984   Cond. No.                         71.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "========================================\n",
      "\n",
      "Dependent Variable: 浏览量\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    浏览量   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.9426\n",
      "Date:                Sat, 20 Jan 2024   Prob (F-statistic):              0.390\n",
      "Time:                        13:01:28   Log-Likelihood:                -50526.\n",
      "No. Observations:                6424   AIC:                         1.011e+05\n",
      "Df Residuals:                    6421   BIC:                         1.011e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                 128.6597    101.260      1.271      0.204     -69.845     327.164\n",
      "predicted_polluted    -25.6363     19.143     -1.339      0.181     -63.162      11.889\n",
      "predicted_authentic    -2.5102     22.172     -0.113      0.910     -45.976      40.955\n",
      "==============================================================================\n",
      "Omnibus:                    23795.003   Durbin-Watson:                   1.950\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):      10879542152.228\n",
      "Skew:                          79.710   Prob(JB):                         0.00\n",
      "Kurtosis:                    6376.417   Cond. No.                         71.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "========================================\n",
      "\n",
      "Dependent Variable: 总评分\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    总评分   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.457\n",
      "Date:                Sat, 20 Jan 2024   Prob (F-statistic):             0.0857\n",
      "Time:                        13:01:28   Log-Likelihood:                -13751.\n",
      "No. Observations:                6424   AIC:                         2.751e+04\n",
      "Df Residuals:                    6421   BIC:                         2.753e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   3.7769      0.331     11.425      0.000       3.129       4.425\n",
      "predicted_polluted     -0.1115      0.062     -1.784      0.074      -0.234       0.011\n",
      "predicted_authentic     0.1123      0.072      1.552      0.121      -0.030       0.254\n",
      "==============================================================================\n",
      "Omnibus:                     1119.406   Durbin-Watson:                   1.814\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1640.214\n",
      "Skew:                          -1.214   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.520   Cond. No.                         71.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"D:\\paper\\secondhand\\iv\\VGG16.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 选择自变量和因变量\n",
    "independent_vars = [\"predicted_polluted\", \"predicted_authentic\"]\n",
    "dependent_vars = [\"想要量\", \"浏览量\", \"总评分\"]\n",
    "\n",
    "# 循环进行回归分析\n",
    "for dependent_var in dependent_vars:\n",
    "    X = df[independent_vars]\n",
    "    y = df[dependent_var]\n",
    "\n",
    "    # 添加常数项\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # 拟合回归模型\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    # 打印回归结果\n",
    "    print(f\"Dependent Variable: {dependent_var}\")\n",
    "    print(model.summary())\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tobit Regression for Dependent Variable: 想要量\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    想要量   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.6821\n",
      "Date:                Sat, 20 Jan 2024   Prob (F-statistic):              0.506\n",
      "Time:                        13:23:29   Log-Likelihood:                -14618.\n",
      "No. Observations:                6424   AIC:                         2.924e+04\n",
      "Df Residuals:                    6421   BIC:                         2.926e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.4545      0.378      1.201      0.230      -0.287       1.196\n",
      "predicted_polluted     -0.0795      0.072     -1.112      0.266      -0.220       0.061\n",
      "predicted_authentic    -0.0165      0.083     -0.200      0.842      -0.179       0.146\n",
      "==============================================================================\n",
      "Omnibus:                    23608.968   Durbin-Watson:                   1.900\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):      10189604134.831\n",
      "Skew:                          77.825   Prob(JB):                         0.00\n",
      "Kurtosis:                    6170.984   Cond. No.                         71.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "========================================\n",
      "\n",
      "Tobit Regression for Dependent Variable: 浏览量\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    浏览量   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.9426\n",
      "Date:                Sat, 20 Jan 2024   Prob (F-statistic):              0.390\n",
      "Time:                        13:23:29   Log-Likelihood:                -50526.\n",
      "No. Observations:                6424   AIC:                         1.011e+05\n",
      "Df Residuals:                    6421   BIC:                         1.011e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                 128.6597    101.260      1.271      0.204     -69.845     327.164\n",
      "predicted_polluted    -25.6363     19.143     -1.339      0.181     -63.162      11.889\n",
      "predicted_authentic    -2.5102     22.172     -0.113      0.910     -45.976      40.955\n",
      "==============================================================================\n",
      "Omnibus:                    23795.003   Durbin-Watson:                   1.950\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):      10879542152.228\n",
      "Skew:                          79.710   Prob(JB):                         0.00\n",
      "Kurtosis:                    6376.417   Cond. No.                         71.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "========================================\n",
      "\n",
      "Tobit Regression for Dependent Variable: 总评分\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    总评分   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.457\n",
      "Date:                Sat, 20 Jan 2024   Prob (F-statistic):             0.0857\n",
      "Time:                        13:23:29   Log-Likelihood:                -13751.\n",
      "No. Observations:                6424   AIC:                         2.751e+04\n",
      "Df Residuals:                    6421   BIC:                         2.753e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   3.7769      0.331     11.425      0.000       3.129       4.425\n",
      "predicted_polluted     -0.1115      0.062     -1.784      0.074      -0.234       0.011\n",
      "predicted_authentic     0.1123      0.072      1.552      0.121      -0.030       0.254\n",
      "==============================================================================\n",
      "Omnibus:                     1119.406   Durbin-Watson:                   1.814\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1640.214\n",
      "Skew:                          -1.214   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.520   Cond. No.                         71.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"D:\\paper\\secondhand\\iv\\VGG16.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 定义变量\n",
    "independent_vars = [\"predicted_polluted\", \"predicted_authentic\"]\n",
    "dependent_vars = [\"想要量\", \"浏览量\", \"总评分\"]\n",
    "\n",
    "# 执行Tobit回归分析\n",
    "for dependent_var in dependent_vars:\n",
    "    X = sm.add_constant(df[independent_vars])\n",
    "    y = df[dependent_var]\n",
    "\n",
    "    # 拟合Tobit回归模型\n",
    "    tobit_model = sm.OLS(y, X, missing='drop')\n",
    "    tobit_results = tobit_model.fit(censor_left=True)  # 设置censor_left=False进行右截断\n",
    "\n",
    "    # 显示Tobit回归结果\n",
    "    print(f\"Tobit Regression for Dependent Variable: {dependent_var}\")\n",
    "    print(tobit_results.summary())\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisson Regression for Dependent Variable: 浏览量\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                    浏览量   No. Observations:                 6424\n",
      "Model:                            GLM   Df Residuals:                     6421\n",
      "Model Family:                 Poisson   Df Model:                            2\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -4.1793e+05\n",
      "Date:                Sat, 20 Jan 2024   Deviance:                   8.1709e+05\n",
      "Time:                        14:43:05   Pearson chi2:                 7.73e+07\n",
      "No. Iterations:                    10   Pseudo R-squ. (CS):             0.9998\n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  10.4294      0.038    274.641      0.000      10.355      10.504\n",
      "predicted_polluted     -1.9671      0.009   -221.307      0.000      -1.984      -1.950\n",
      "predicted_authentic     0.0124      0.009      1.391      0.164      -0.005       0.030\n",
      "=======================================================================================\n",
      "\n",
      "========================================\n",
      "\n",
      "Poisson Regression for Dependent Variable: 想要量\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                    想要量   No. Observations:                 6424\n",
      "Model:                            GLM   Df Residuals:                     6421\n",
      "Model Family:                 Poisson   Df Model:                            2\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2465.8\n",
      "Date:                Sat, 20 Jan 2024   Deviance:                       4511.8\n",
      "Time:                        14:43:05   Pearson chi2:                 2.89e+05\n",
      "No. Iterations:                     9   Pseudo R-squ. (CS):            0.01699\n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   2.6643      0.565      4.719      0.000       1.558       3.771\n",
      "predicted_polluted     -1.1862      0.121     -9.778      0.000      -1.424      -0.948\n",
      "predicted_authentic    -0.1611      0.131     -1.231      0.218      -0.418       0.095\n",
      "=======================================================================================\n",
      "\n",
      "========================================\n",
      "\n",
      "Poisson Regression for Dependent Variable: 总评分\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                    总评分   No. Observations:                 6424\n",
      "Model:                            GLM   Df Residuals:                     6421\n",
      "Model Family:                 Poisson   Df Model:                            2\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -14853.\n",
      "Date:                Sat, 20 Jan 2024   Deviance:                       12776.\n",
      "Time:                        14:43:05   Pearson chi2:                 7.37e+03\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):          0.0008777\n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   1.3294      0.084     15.909      0.000       1.166       1.493\n",
      "predicted_polluted     -0.0303      0.016     -1.911      0.056      -0.061       0.001\n",
      "predicted_authentic     0.0304      0.018      1.663      0.096      -0.005       0.066\n",
      "=======================================================================================\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"D:\\paper\\secondhand\\iv\\VGG16.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 定义自变量\n",
    "independent_vars = [\"predicted_polluted\", \"predicted_authentic\"]\n",
    "\n",
    "# 定义因变量列表\n",
    "dependent_vars = [\"浏览量\", \"想要量\", \"总评分\"]\n",
    "\n",
    "# 拟合泊松回归模型并显示结果\n",
    "for dependent_var in dependent_vars:\n",
    "    # 添加截距项\n",
    "    X = sm.add_constant(df[independent_vars])\n",
    "    \n",
    "    # 拟合泊松回归模型\n",
    "    poisson_model = sm.GLM(df[dependent_var], X, family=sm.families.Poisson()).fit()\n",
    "\n",
    "    # 显示泊松回归结果\n",
    "    print(f\"Poisson Regression for Dependent Variable: {dependent_var}\")\n",
    "    print(poisson_model.summary())\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'polluted', ' authentic', 'Image',\n",
       "       'Person_Detected', 'HasUpperBody', '_id', 'infoId', 'metric', 'title',\n",
       "       'price', 'infoImage', 'headImg', 'nickName', 'uid', 'adTicket',\n",
       "       'userStatus', 'labelText', '所有图片链接', '商品原价', '是否包邮', '商品标签', '商品说明',\n",
       "       '发布地', '想要量', '浏览量', '留言数', '总评分', '评论数', '交易次数', '好评率', '处罚记录',\n",
       "       '关联账号信息', '实人认证', '微信支付分', '近期卖出', '发货后被退货', '近期买入', '申请退款次数', '交易纠纷数',\n",
       "       '恶意退货退款', '恶意砍价', '不诚信交易', '骚扰辱骂', '售假劣质品被举报次数', '被举报成立次数', '欺诈被举报次数',\n",
       "       '粉丝', '关注', '勋章', '卖家简介', '全部', '来自买家', '来自卖家', '有图', '好评', '中评', '差评',\n",
       "       'predicted_polluted', 'predicted_authentic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([2501], dtype='int64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Image'] == 'head_1718129828196389888.png'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                log_浏览量   No. Observations:                 6424\n",
      "Model:                            GLM   Df Residuals:                     6421\n",
      "Model Family:        NegativeBinomial   Df Model:                            2\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -10461.\n",
      "Date:                Sat, 20 Jan 2024   Deviance:                       1018.5\n",
      "Time:                        18:36:17   Pearson chi2:                 1.22e+03\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):          3.623e-05\n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.2608      0.210      1.239      0.215      -0.152       0.673\n",
      "predicted_polluted      0.0191      0.040      0.481      0.631      -0.059       0.097\n",
      "predicted_authentic    -0.0017      0.046     -0.037      0.971      -0.092       0.089\n",
      "=======================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 df 是包含浏览量、想要量和其他变量的 DataFrame，列名分别为 '浏览量'、'想要量' 和其他变量\n",
    "# Replace column names accordingly\n",
    "\n",
    "# 对因变量进行对数化\n",
    "df['log_浏览量'] = np.log1p(df['浏览量'])\n",
    "df['log_想要量'] = np.log1p(df['想要量'])\n",
    "# # 设置图形大小\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # 创建浏览量的分布图\n",
    "# plt.subplot(2, 1, 1)\n",
    "# sns.histplot(df['log_浏览量'], bins=30, kde=True, color='skyblue')\n",
    "# plt.title('log(1 + 浏览量) 分布图')\n",
    "\n",
    "# # 创建想要量的分布图\n",
    "# plt.subplot(2, 1, 2)\n",
    "# sns.histplot(df['想要量'], bins=30, kde=True, color='salmon')\n",
    "# plt.title('想要量分布图')\n",
    "\n",
    "# # 调整布局\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # 显示图形\n",
    "# plt.show()\n",
    "\n",
    "# 构建广义线性模型\n",
    "X = df[['predicted_polluted', 'predicted_authentic']]  # 选择你的解释变量\n",
    "X = sm.add_constant(X)  # 添加常数列\n",
    "y = df['log_浏览量']\n",
    "\n",
    "# 使用负二项分布和对数链接函数进行广义线性回归\n",
    "glm_model = sm.GLM(y, X, family=sm.families.NegativeBinomial())\n",
    "glm_results = glm_model.fit()\n",
    "\n",
    "# 输出回归结果\n",
    "print(glm_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                log_想要量   No. Observations:                 6424\n",
      "Model:                            GLM   Df Residuals:                     6421\n",
      "Model Family:        NegativeBinomial   Df Model:                            2\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -745.25\n",
      "Date:                Sat, 20 Jan 2024   Deviance:                       1017.7\n",
      "Time:                        18:36:42   Pearson chi2:                 6.43e+03\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):          0.0001139\n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  -4.0973      1.040     -3.938      0.000      -6.136      -2.058\n",
      "predicted_polluted      0.1590      0.194      0.819      0.413      -0.222       0.540\n",
      "predicted_authentic    -0.0797      0.228     -0.350      0.727      -0.527       0.367\n",
      "=======================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n"
     ]
    }
   ],
   "source": [
    "# 构建广义线性模型\n",
    "X = df[['predicted_polluted', 'predicted_authentic']]  # 选择你的解释变量\n",
    "X = sm.add_constant(X)  # 添加常数列\n",
    "y = df['log_想要量']\n",
    "\n",
    "# 使用负二项分布和对数链接函数进行广义线性回归\n",
    "glm_model = sm.GLM(y, X, family=sm.families.NegativeBinomial())\n",
    "glm_results = glm_model.fit()\n",
    "\n",
    "# 输出回归结果\n",
    "print(glm_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in log\n",
      "Inverting hessian failed, no bse or cov_params available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 3.205450\n",
      "         Iterations: 25\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in log\n",
      "invalid value encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ZeroInflatedNegativeBinomialP Regression Results                    \n",
      "=========================================================================================\n",
      "Dep. Variable:                               浏览量   No. Observations:                 6424\n",
      "Model:             ZeroInflatedNegativeBinomialP   Df Residuals:                     6421\n",
      "Method:                                      MLE   Df Model:                            2\n",
      "Date:                           Sat, 20 Jan 2024   Pseudo R-squ.:                 0.02559\n",
      "Time:                                   18:38:14   Log-Likelihood:                -20592.\n",
      "converged:                                  True   LL-Null:                       -21133.\n",
      "Covariance Type:                       nonrobust   LLR p-value:                1.377e-235\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "inflate_const         -24.0608   1539.894     -0.016      0.988   -3042.198    2994.076\n",
      "const                   6.4082      0.161     39.736      0.000       6.092       6.724\n",
      "predicted_polluted     -1.3294      0.038    -34.709      0.000      -1.404      -1.254\n",
      "predicted_authentic     0.4538      0.048      9.504      0.000       0.360       0.547\n",
      "alpha                   2.3032      0.035     65.506      0.000       2.234       2.372\n",
      "=======================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inverting hessian failed, no bse or cov_params available\n",
      "Inverting hessian failed, no bse or cov_params available\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 df 是包含浏览量、想要量和其他变量的 DataFrame，列名分别为 '浏览量'、'想要量' 和其他变量\n",
    "# Replace column names accordingly\n",
    "\n",
    "\n",
    "\n",
    "# 构建零膨胀负二项回归模型\n",
    "X = df[['predicted_polluted', 'predicted_authentic']]  # 选择你的解释变量\n",
    "X = sm.add_constant(X)  # 添加常数列\n",
    "y = df['浏览量']  # 这里使用原始浏览量作为因变量\n",
    "\n",
    "# 使用零膨胀负二项回归模型\n",
    "zinb_model = sm.ZeroInflatedNegativeBinomialP(y, X)\n",
    "zinb_results = zinb_model.fit()\n",
    "\n",
    "# 输出回归结果\n",
    "print(zinb_results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in log\n",
      "invalid value encountered in log\n",
      "invalid value encountered in log\n",
      "invalid value encountered in log\n",
      "invalid value encountered in log\n",
      "overflow encountered in exp\n",
      "overflow encountered in exp\n",
      "invalid value encountered in multiply\n",
      "divide by zero encountered in log\n",
      "invalid value encountered in multiply\n",
      "invalid value encountered in log\n",
      "invalid value encountered in log\n",
      "invalid value encountered in log\n",
      "invalid value encountered in log\n",
      "invalid value encountered in log\n",
      "Desired error not necessarily achieved due to precision loss.\n",
      "Inverting hessian failed, no bse or cov_params available\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: nan\n",
      "         Iterations: 1\n",
      "         Function evaluations: 112\n",
      "         Gradient evaluations: 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in log\n",
      "invalid value encountered in log\n",
      "Inverting hessian failed, no bse or cov_params available\n",
      "invalid value encountered in log\n",
      "invalid value encountered in log\n",
      "Inverting hessian failed, no bse or cov_params available\n",
      "invalid value encountered in log\n",
      "overflow encountered in exp\n",
      "invalid value encountered in multiply\n",
      "divide by zero encountered in log\n",
      "invalid value encountered in multiply\n",
      "overflow encountered in exp\n",
      "invalid value encountered in log\n",
      "invalid value encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ZeroInflatedNegativeBinomialP Regression Results                    \n",
      "=========================================================================================\n",
      "Dep. Variable:                           log_浏览量   No. Observations:                 6424\n",
      "Model:             ZeroInflatedNegativeBinomialP   Df Residuals:                     6421\n",
      "Method:                                      MLE   Df Model:                            2\n",
      "Date:                           Sat, 20 Jan 2024   Pseudo R-squ.:                     nan\n",
      "Time:                                   18:43:46   Log-Likelihood:                    nan\n",
      "converged:                                 False   LL-Null:                           nan\n",
      "Covariance Type:                       nonrobust   LLR p-value:                       nan\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "inflate_const        -510.7245        nan        nan        nan         nan         nan\n",
      "const                   3.4042        nan        nan        nan         nan         nan\n",
      "predicted_polluted     11.5448        nan        nan        nan         nan         nan\n",
      "predicted_authentic    10.7924        nan        nan        nan         nan         nan\n",
      "alpha                -390.4031        nan        nan        nan         nan         nan\n",
      "=======================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in log\n",
      "invalid value encountered in log\n",
      "Inverting hessian failed, no bse or cov_params available\n"
     ]
    }
   ],
   "source": [
    "# 构建零膨胀负二项回归模型\n",
    "X = df[['predicted_polluted', 'predicted_authentic']]  # 选择你的解释变量\n",
    "X = sm.add_constant(X)  # 添加常数列\n",
    "y = df['log_浏览量']  # 这里使用原始浏览量作为因变量\n",
    "\n",
    "# 使用零膨胀负二项回归模型\n",
    "zinb_model = sm.ZeroInflatedNegativeBinomialP(y, X)\n",
    "zinb_results = zinb_model.fit()\n",
    "\n",
    "# 输出回归结果\n",
    "print(zinb_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold=4.135162089977861\n"
     ]
    }
   ],
   "source": [
    "# 读取颜色特征数据\n",
    "color_file_path = r\"D:\\paper\\secondhand\\color.csv\"\n",
    "\n",
    "df_color = pd.read_csv(color_file_path).dropna()\n",
    "\n",
    "# 读取主数据\n",
    "main_data_file_path = r\"D:\\paper\\secondhand\\iv\\VGG16.xlsx\"\n",
    "df_main = pd.read_excel(main_data_file_path)\n",
    "\n",
    "\n",
    "# 读取合并后的数据\n",
    "merged_df = pd.merge(df_main, df_color, left_on='Image', right_on='image', how='inner')\n",
    "merged_df['predicted_polluted'] = merged_df['predicted_polluted'].apply(pd.to_numeric, errors='coerce', downcast='float')\n",
    "\n",
    "# 选择颜色特征作为自变量\n",
    "features = merged_df[['RGB_R_mean', 'RGB_R_median', 'RGB_R_std_dev', 'RGB_R_min', 'RGB_R_max', 'RGB_G_mean', 'RGB_G_median', 'RGB_G_std_dev', 'RGB_G_min', 'RGB_G_max', 'RGB_B_mean', 'RGB_B_median', 'RGB_B_std_dev', 'RGB_B_min', 'RGB_B_max', 'HSV_H_mean', 'HSV_H_std_dev', 'HSV_S_mean', 'HSV_S_std_dev', 'HSV_V_mean', 'HSV_V_std_dev', 'XYZ_X_mean', 'XYZ_X_std_dev', 'XYZ_Y_mean', 'XYZ_Y_std_dev', 'XYZ_Z_mean', 'XYZ_Z_std_dev', 'Lab_L_mean', 'Lab_L_std_dev', 'Lab_a_mean', 'Lab_a_std_dev', 'Lab_b_mean', 'Lab_b_std_dev', 'gray_mean', 'gray_std_dev', 'contrast_range', 'contrast_range_lower', 'contrast_range_upper', 'contrast_n_peak', 'contrast_peak_distance', 'colorful', 'colorful_emd', 'black', 'blue', 'brown', 'gray', 'green', 'orange', 'pink', 'purple', 'red', 'white', 'yellow', 'color_shannon', 'color_simpson', 'hue_count']]\n",
    "merged_df[features.columns] = merged_df[features.columns].apply(pd.to_numeric, errors='coerce', downcast='float')\n",
    "\n",
    "# 设置阈值将问题转换为二进制分类任务\n",
    "threshold = merged_df['predicted_polluted'].mean()  # Set your threshold based on your problem\n",
    "print(f'threshold={threshold}')\n",
    "df_color[features.columns] = df_color[features.columns].apply(pd.to_numeric, errors='coerce', downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert continuous labels to binary classes\n",
    "labels_binary = (merged_df['predicted_polluted'] > threshold).astype(float)\n",
    "\n",
    "# 初始化XGBoost分类器\n",
    "classifier = xgboost.train({\"learning_rate\": 0.01}, xgboost.DMatrix(merged_df[features.columns], label=labels_binary), 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:48:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x684 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 解释模型预测\n",
    "explainer = shap.TreeExplainer(classifier)\n",
    "shap_values = explainer.shap_values(merged_df[features.columns])\n",
    "\n",
    "# 绘制汇总图\n",
    "shap.summary_plot(shap_values, merged_df[features.columns], plot_type=\"bar\", feature_names=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1054928e-03,  4.6505826e-04,  2.6006741e-02, ...,\n",
       "         6.5547256e-03, -8.2143175e-05,  6.7516736e-04],\n",
       "       [-1.1054928e-03,  4.6505826e-04,  2.6006741e-02, ...,\n",
       "         6.5547256e-03, -8.2143175e-05,  6.7516736e-04],\n",
       "       [-4.8953859e-04,  2.1067346e-03,  2.0520866e-02, ...,\n",
       "        -5.2912580e-04,  1.5508766e-04,  6.3898816e-04],\n",
       "       ...,\n",
       "       [-5.2801147e-04,  2.1171933e-03,  3.0171296e-02, ...,\n",
       "         4.5013246e-03,  1.2992751e-03,  1.1486595e-04],\n",
       "       [-5.8372243e-04,  1.5931758e-03,  2.8738277e-02, ...,\n",
       "        -3.0016445e-03, -1.0407052e-03, -1.3920411e-03],\n",
       "       [ 7.1225199e-04, -4.2461688e-03,  2.1429539e-02, ...,\n",
       "         7.8646920e-04, -2.4525623e-04, -9.5895164e-05]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RGB_R_mean', 'RGB_R_median', 'RGB_R_std_dev', 'RGB_R_min', 'RGB_R_max',\n",
       "       'RGB_G_mean', 'RGB_G_median', 'RGB_G_std_dev', 'RGB_G_min', 'RGB_G_max',\n",
       "       'RGB_B_mean', 'RGB_B_median', 'RGB_B_std_dev', 'RGB_B_min', 'RGB_B_max',\n",
       "       'HSV_H_mean', 'HSV_H_std_dev', 'HSV_S_mean', 'HSV_S_std_dev',\n",
       "       'HSV_V_mean', 'HSV_V_std_dev', 'XYZ_X_mean', 'XYZ_X_std_dev',\n",
       "       'XYZ_Y_mean', 'XYZ_Y_std_dev', 'XYZ_Z_mean', 'XYZ_Z_std_dev',\n",
       "       'Lab_L_mean', 'Lab_L_std_dev', 'Lab_a_mean', 'Lab_a_std_dev',\n",
       "       'Lab_b_mean', 'Lab_b_std_dev', 'gray_mean', 'gray_std_dev',\n",
       "       'contrast_range', 'contrast_range_lower', 'contrast_range_upper',\n",
       "       'contrast_n_peak', 'contrast_peak_distance', 'colorful', 'colorful_emd',\n",
       "       'black', 'blue', 'brown', 'gray', 'green', 'orange', 'pink', 'purple',\n",
       "       'red', 'white', 'yellow', 'color_shannon', 'color_simpson',\n",
       "       'hue_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
